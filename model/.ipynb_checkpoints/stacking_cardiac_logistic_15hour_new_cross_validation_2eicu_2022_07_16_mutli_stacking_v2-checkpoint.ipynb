{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeline: (21540, 90)\n",
      "baseline: (21540, 70)\n",
      "timeline: (42320, 15, 6)\n",
      "baseline: (42320, 70)\n",
      "label: (42320,)\n",
      "timeline: (5384, 15, 6)\n",
      "baseline: (5384, 70)\n",
      "label: (5384, 1)\n",
      "timeline_no_smote: (21540, 15, 6)\n",
      "baseline_no_smote: (21540, 70)\n",
      "label_no_smote: (21540, 1)\n",
      "timeline_nr: (760, 15, 6)\n",
      "label_nr: (760,)\n"
     ]
    }
   ],
   "source": [
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(0)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(2)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(24)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(26)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "#from keras import backend as K\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "\n",
    "from sklearn import preprocessing  #用來標準化刻度\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import logcosh, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Import Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from time import time\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "####################################################################################  x_lstm_validation\n",
    "\n",
    "T=15\n",
    "\n",
    "train_cardiac_total=pd.read_csv(\"mimic_ca_vital_sign_train_\"+str(T)+\"hours.csv\")\n",
    "test_cardiac_total=pd.read_csv(\"mimic_ca_vital_sign_test_\"+str(T)+\"hours.csv\")\n",
    "train_cardiac_base_total=pd.read_csv(\"mimic_ca_baseline_total_v2.csv\")\n",
    "\n",
    "eicu_cardiac_total=pd.read_csv(\"eicu_total_\"+str(T)+\"hours.csv\")\n",
    "\n",
    "total_train=21540 #control+event\n",
    "total_test=5384 #control+event\n",
    "train_control=21160 #control\n",
    "\n",
    "\n",
    "var=6\n",
    "random=32\n",
    "smote_ratio=1\n",
    "near_ratio=1\n",
    "EPOCH = 3                    # number of epochs\n",
    "BATCH = 32                      # batch size\n",
    "\n",
    "dropout=0.4\n",
    "LR = 0.001                           # learning rate of the gradient descent\n",
    "LAMBD = 0.001                       # lambda in L2 regularizaion\n",
    "\n",
    "#####################################################################################\n",
    "train_cardiac_base_total=train_cardiac_base_total.drop(['subject_id'],axis=1)\n",
    "train_cardiac_base_total=train_cardiac_base_total.drop(['hadm_id'],axis=1)\n",
    "train_cardiac_base_total=train_cardiac_base_total.drop(['stay_id'],axis=1)\n",
    "train_cardiac_base_total=train_cardiac_base_total.drop(['los'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['CA'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['hospDIED'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['cardR'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['DNR'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['CMO'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['DNRDNI'],axis=1)\n",
    "\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['DNI'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['FullCode'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['indextime'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['ccs9'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['ccs10'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['cardRv2'],axis=1)\n",
    "\n",
    "###############CXR##############\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Atelectasis'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Cardiomegaly'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Consolidation'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Edema'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Enlarged Cardiomediastinum'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Fracture'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Lung Lesion'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Lung Opacity'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['No Finding'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Pleural Effusion'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Pleural Other'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Pneumonia'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Pneumothorax'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Support Devices'],axis=1)\n",
    "###############CXR##############\n",
    "\n",
    "#train_cardiac_base_total=pd.get_dummies(data=train_cardiac_base_total,columns=[\"first_careunit\",\"ethnicity\",\"BMI\"])\n",
    "train_cardiac_base_total=pd.get_dummies(data=train_cardiac_base_total,columns=[\"first_careunit\",\"ethnicity\"])\n",
    "\n",
    "\n",
    "####################################################################\n",
    "df_train_base=train_cardiac_base_total[:total_train]\n",
    "y_train=df_train_base[['eventV3']].values   #取train_labels\n",
    "y_train_nr=df_train_base[['eventV3']].values   #取train_labels\n",
    "y_train_base=df_train_base[['eventV3']].values   #取train_labels\n",
    "y_train_no_smote=df_train_base[['eventV3']].values   #取train_labels\n",
    "df_train_base=df_train_base.drop(['eventV3'],axis=1)\n",
    "train_features=df_train_base.values\n",
    "\n",
    "df_test_base=train_cardiac_base_total[total_train:]\n",
    "y_test=df_test_base[['eventV3']].values   #取test_labels\n",
    "y_test_log=df_test_base['eventV3'].values   #取test_labels\n",
    "df_test_base=df_test_base.drop(['eventV3'],axis=1)\n",
    "test_features=df_test_base.values\n",
    "\n",
    "minmax_scale =preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "x_train_base=minmax_scale.fit_transform(train_features)\n",
    "x_test_base=minmax_scale.fit_transform(test_features)\n",
    "\n",
    "x_train_base_no_smote=minmax_scale.fit_transform(train_features)\n",
    "\n",
    "#x_train_base=train_features\n",
    "#x_test_base=test_features\n",
    "\n",
    "sm = SMOTE(random_state=random, sampling_strategy=smote_ratio)\n",
    "nr = NearMiss(sampling_strategy=near_ratio) \n",
    "\n",
    "x_train_base, y_train_base = sm.fit_sample(x_train_base, y_train_base.ravel())\n",
    "#x_train_base, y_train_base = nr.fit_sample(x_train_base, y_train_base.ravel())\n",
    "\n",
    "train_cardiac_total=train_cardiac_total[['vHR','vRR','vsbp','vdbp','vmbp','vspo2']]    \n",
    "train_cardiac_total=np.array(train_cardiac_total).reshape(total_train,T*var) #轉二維  array\n",
    "train_cardiac_total= pd.DataFrame(train_cardiac_total)\n",
    "\n",
    "x_test_lstm=test_cardiac_total[['vHR','vRR','vsbp','vdbp','vmbp','vspo2']].values \n",
    "#x_test_lstm=minmax_scale.fit_transform(x_test_lstm)  #規一化\n",
    "x_test_lstm=np.array(x_test_lstm).reshape(total_test,T,var) \n",
    "\n",
    "x_train_lstm, y_train = sm.fit_sample(train_cardiac_total, y_train.ravel())\n",
    "\n",
    "x_train_lstm_nr, y_train_nr = nr.fit_sample(train_cardiac_total, y_train_nr.ravel())\n",
    "\n",
    "#x_train_lstm=minmax_scale.fit_transform(x_train_lstm)  #規一化\n",
    "\n",
    "x_train_lstm=np.array(x_train_lstm).reshape(x_train_lstm.shape[0],T,var) #轉三維  total\n",
    "\n",
    "x_train_lstm_nr=np.array(x_train_lstm_nr).reshape(x_train_lstm_nr.shape[0],T,var) #轉三維  total\n",
    "\n",
    "x_train_lstm_no_smote=np.array(train_cardiac_total).reshape(train_cardiac_total.shape[0],T,var) #轉三維  total\n",
    "\n",
    "print('timeline:',train_cardiac_total.shape)\n",
    "print('baseline:',df_train_base.shape)\n",
    "\n",
    "print('timeline:',x_train_lstm.shape)\n",
    "print('baseline:',x_train_base.shape)\n",
    "print('label:',y_train.shape)\n",
    "\n",
    "print('timeline:',x_test_lstm.shape)\n",
    "print('baseline:',x_test_base.shape)\n",
    "print('label:',y_test.shape)\n",
    "\n",
    "print('timeline_no_smote:',x_train_lstm_no_smote.shape)\n",
    "print('baseline_no_smote:',x_train_base_no_smote.shape)\n",
    "print('label_no_smote:',y_train_no_smote.shape)\n",
    "\n",
    "\n",
    "print('timeline_nr:',x_train_lstm_nr.shape)\n",
    "print('label_nr:',y_train_nr.shape)\n",
    "#print(df_train_base.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42320, 15, 6)\n",
      "(42320,)\n",
      "layers=[8, 8, 8, 1], train_examples=42320, test_examples=5384\n",
      "batch = 32, timesteps = 15, features = 6, epochs = 3\n",
      "lr = 0.001, lambda = 0.001, dropout = 1, recurr_dropout = 1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 15, 8)             480       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 15, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 15, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,673\n",
      "Trainable params: 1,625\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 33856 samples, validate on 8464 samples\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "print(x_train_lstm.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm.shape[0]           # number of training examples (2D)\n",
    "#M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_smote = Sequential()\n",
    "\n",
    "model_smote.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_smote.add(Dropout(dropout))\n",
    "model_smote.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_smote.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_smote.add(Dropout(dropout))\n",
    "model_smote.add(BatchNormalization())\n",
    "\n",
    "model_smote.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_smote.add(Dropout(dropout))\n",
    "model_smote.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_smote.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_smote.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_smote.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_smote.fit(x_train_lstm, y_train,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0.2,\n",
    "                    #validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_smote.evaluate(x_train_lstm, y_train,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_smote.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_smote= model_smote.predict(x_test_lstm)\n",
    "\n",
    "predict_test_smote=[]\n",
    "for i in range(y_pred_smote.shape[0]): \n",
    "    if y_pred_smote[i]>0.5:\n",
    "        predict_test_smote.append(1)\n",
    "    else:\n",
    "        predict_test_smote.append(0)\n",
    "predict_test_smote = np.array(predict_test_smote)\n",
    "print(predict_test_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_smote,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_smote)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "accuracy= (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,1]+cm1[1,0])   #FPR\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('accuracy:',accuracy)\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_test, y_pred_smote) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('smote')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_lstm_nr.shape)\n",
    "print(y_train_nr.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_nr.shape[0]           # number of training examples (2D)\n",
    "#M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_nr = Sequential()\n",
    "\n",
    "model_nr.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_nr.add(Dropout(dropout))\n",
    "model_nr.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_nr.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_nr.add(Dropout(dropout))\n",
    "model_nr.add(BatchNormalization())\n",
    "\n",
    "model_nr.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_nr.add(Dropout(dropout))\n",
    "model_nr.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_nr.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_nr.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_nr.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_nr.fit(x_train_lstm_nr, y_train_nr,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0.2,\n",
    "                    #validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_nr.evaluate(x_train_lstm_nr, y_train_nr,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_nr.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nr= model_nr.predict(x_test_lstm)\n",
    "\n",
    "predict_test_nr=[]\n",
    "for i in range(y_pred_nr.shape[0]): \n",
    "    if y_pred_nr[i]>0.5:\n",
    "        predict_test_nr.append(1)\n",
    "    else:\n",
    "        predict_test_nr.append(0)\n",
    "predict_test_nr = np.array(predict_test_nr)\n",
    "print(predict_test_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_nr,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_nr)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "accuracy= (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,1]+cm1[1,0])   #FPR\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('accuracy:',accuracy)\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_test, y_pred_nr) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('nr')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo1\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[part_0:], x_event_1[part_1:]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[:part_0], x_event_1[:part_1]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[part_0:], y_event_1[part_1:]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[:part_0], y_event_1[:part_1]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_1.add(Dropout(dropout))\n",
    "model_1.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_1.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_1.add(Dropout(dropout))\n",
    "model_1.add(BatchNormalization())\n",
    "\n",
    "model_1.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_1.add(Dropout(dropout))\n",
    "model_1.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_1.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_1.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_1.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_1.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_1.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_1.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred1= model_1.predict(x_test_lstm)\n",
    "predict_train_lstm1=model_1.predict(x_train_lstm)\n",
    "\n",
    "test_acc_1=test_acc\n",
    "test_precision_1=test_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_1=[]\n",
    "for i in range(y_pred1.shape[0]): \n",
    "    if y_pred1[i]>0.5:\n",
    "        predict_test_1.append(1)\n",
    "    else:\n",
    "        predict_test_1.append(0)\n",
    "predict_test_1 = np.array(predict_test_1)\n",
    "print(predict_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_1,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_1)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo2\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[:part_0], x_event_1[:part_1],x_event_0[2*part_0:],x_event_1[2*part_1:]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[part_0:2*part_0], x_event_1[part_1:2*part_1]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[:part_0], y_event_1[:part_1],y_event_0[2*part_0:], y_event_1[2*part_1:]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[part_0:2*part_0], y_event_1[part_1:2*part_1]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "             #  dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_2.add(Dropout(dropout))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_2.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "             #  dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_2.add(Dropout(dropout))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_2.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_2.add(Dropout(dropout))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_2.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_2.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_2.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_2.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_2.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_2.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred2= model_2.predict(x_test_lstm)\n",
    "predict_train_lstm2=model_2.predict(x_train_lstm)\n",
    "\n",
    "test_acc_2=test_acc\n",
    "test_precision_2=test_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_2=[]\n",
    "for i in range(y_pred2.shape[0]): \n",
    "    if y_pred2[i]>0.5:\n",
    "        predict_test_2.append(1)\n",
    "    else:\n",
    "        predict_test_2.append(0)\n",
    "predict_test_2 = np.array(predict_test_2)\n",
    "print(predict_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_2,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_2)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])   \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo3\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[:2*part_0], x_event_1[:2*part_1],x_event_0[3*part_0:],x_event_1[3*part_1:]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[2*part_0:3*part_0], x_event_1[2*part_1:3*part_1]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[:2*part_0], y_event_1[:2*part_1],y_event_0[3*part_0:], y_event_1[3*part_1:]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[2*part_0:3*part_0], y_event_1[2*part_1:3*part_1]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_3.add(Dropout(dropout))\n",
    "model_3.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_3.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "             #  dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_3.add(Dropout(dropout))\n",
    "model_3.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_3.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "             #  dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_3.add(Dropout(dropout))\n",
    "model_3.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_3.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_3.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_3.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_3.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_3.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_3.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred3= model_3.predict(x_test_lstm)\n",
    "predict_train_lstm3=model_3.predict(x_train_lstm)\n",
    "\n",
    "test_acc_3=test_acc\n",
    "test_precision_3=test_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_3=[]\n",
    "for i in range(y_pred3.shape[0]): \n",
    "    if y_pred3[i]>0.5:\n",
    "        predict_test_3.append(1)\n",
    "    else:\n",
    "        predict_test_3.append(0)\n",
    "predict_test_3 = np.array(predict_test_3)\n",
    "print(predict_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_3,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_3)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo4\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[:3*part_0], x_event_1[:3*part_1],x_event_0[4*part_0:],x_event_1[4*part_1:]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[3*part_0:4*part_0], x_event_1[3*part_1:4*part_1]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[:3*part_0], y_event_1[:3*part_1],y_event_0[4*part_0:], y_event_1[4*part_1:]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[3*part_0:4*part_0], y_event_1[3*part_1:4*part_1]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_4 = Sequential()\n",
    "\n",
    "model_4.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_4.add(Dropout(dropout))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_4.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "            #   dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_4.add(Dropout(dropout))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_4.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "           #    dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_4.add(Dropout(dropout))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_4.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_4.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_4.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_4.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_4.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_4.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred4= model_4.predict(x_test_lstm)\n",
    "predict_train_lstm4=model_4.predict(x_train_lstm)\n",
    "\n",
    "test_acc_4=test_acc\n",
    "test_precision_4=test_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_4=[]\n",
    "for i in range(y_pred4.shape[0]): \n",
    "    if y_pred4[i]>0.5:\n",
    "        predict_test_4.append(1)\n",
    "    else:\n",
    "        predict_test_4.append(0)\n",
    "predict_test_4 = np.array(predict_test_4)\n",
    "print(predict_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_4,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_4)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])   \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo5\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[:4*part_0], x_event_1[:4*part_1]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[4*part_0:], x_event_1[4*part_1:]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[:4*part_0], y_event_1[:4*part_1]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[4*part_0:], y_event_1[4*part_1:]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_5 = Sequential()\n",
    "\n",
    "model_5.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "            #   dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_5.add(Dropout(dropout))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_5.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "            #   dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_5.add(Dropout(dropout))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_5.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "           #    dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_5.add(Dropout(dropout))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_5.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_5.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_5.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_5.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_5.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_5.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred5= model_5.predict(x_test_lstm)\n",
    "predict_train_lstm5=model_5.predict(x_train_lstm)\n",
    "\n",
    "test_acc_5=test_acc\n",
    "test_precision_5=test_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_5=[]\n",
    "for i in range(y_pred5.shape[0]): \n",
    "    if y_pred5[i]>0.5:\n",
    "        predict_test_5.append(1)\n",
    "    else:\n",
    "        predict_test_5.append(0)\n",
    "predict_test_5 = np.array(predict_test_5)\n",
    "print(predict_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_5,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_5)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_temp=np.append(y_pred1,y_pred2)\n",
    "y_pred_temp=np.append(y_pred_temp,y_pred3)\n",
    "y_pred_temp=np.append(y_pred_temp,y_pred4)\n",
    "y_pred_temp=np.append(y_pred_temp,y_pred5)\n",
    "\n",
    "predict_train_temp=np.append(predict_train_lstm1,predict_train_lstm2)\n",
    "predict_train_temp=np.append(predict_train_temp,predict_train_lstm3)\n",
    "predict_train_temp=np.append(predict_train_temp,predict_train_lstm4)\n",
    "predict_train_temp=np.append(predict_train_temp,predict_train_lstm5)\n",
    "\n",
    "y_pred=np.array(y_pred_temp).reshape(x_test_lstm.shape[0],5, order='F') #轉維\n",
    "predict_train_lstm=np.array(predict_train_temp).reshape(x_train_lstm.shape[0],5, order='F') #轉維\n",
    "\n",
    "y_pred= np.mean(y_pred, axis=1)\n",
    "predict_train_lstm= np.mean(predict_train_lstm, axis=1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test=[]\n",
    "for i in range(y_pred.shape[0]): \n",
    "    if y_pred[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "print(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "accuracy_5_fold=(cm1[0,0]+cm1[1,1])/(cm1[1,1]+cm1[0,0]+cm1[0,1]+cm1[1,0])\n",
    "\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[0,1])  \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n",
    "\n",
    "\n",
    "y_pred=np.array(y_pred).reshape(total_test)\n",
    "\n",
    "flag=0\n",
    "total_predict=0\n",
    "for i in range(y_pred.shape[0]): \n",
    "      if y_pred[i]>0.5:\n",
    "            total_predict=total_predict+y_pred[i]\n",
    "            flag=flag+1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_test, y_pred) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('5 fold LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy : %0.2f' %accuracy_5_fold)  #accuracy\n",
    "print('AUC : %0.2f' % roc_auc)  #AUC\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n",
    "#print('f1_score :%0.2f' %test_f1_score)  #f1_score\n",
    "print(total_predict/flag*100)  #score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics,ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import model_selection\n",
    "\n",
    "forest = ensemble.RandomForestClassifier()\n",
    "\n",
    "rf_params = {\n",
    "'n_estimators': [15,20,25],\n",
    "'max_depth': [4,5,6,7]\n",
    " }\n",
    "\n",
    "forest = model_selection.GridSearchCV(forest, rf_params, cv=5)\n",
    "forest = forest.fit(x_train_base, y_train)\n",
    "\n",
    "prob_predict_y_validation1 = forest.predict_proba(x_train_base)#给出带有概率值的结果，每个点所有label的概率和为1\n",
    "prob_predict_y_validation = forest.predict_proba(x_test_base)#给出带有概率值的结果，每个点所有label的概率和为1\n",
    "\n",
    "\n",
    "y_score = prob_predict_y_validation[:, 1]\n",
    "# 預測\n",
    "predict_train_rf = prob_predict_y_validation1[:, 1]\n",
    "\n",
    "test_y_predicted = forest.predict(x_test_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc  ###計算roc和auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def roc_curve_and_score(y_test, pred_proba):\n",
    "    fpr, tpr, _ = roc_curve(y_test.ravel(), pred_proba.ravel())\n",
    "    roc_auc = roc_auc_score(y_test.ravel(), pred_proba.ravel())\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "#plt.grid()\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_score)\n",
    "plt.plot(fpr, tpr, color='#00db00', lw=2,\n",
    "         label='Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "plt.title('Random Forest')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test=[]\n",
    "for i in range(y_score.shape[0]): \n",
    "    if y_score[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "Accuracy  = (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,0]+cm1[1,1])   \n",
    "\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "\n",
    "print('Accuracy : %0.2f' %Accuracy)  #Accuracy\n",
    "print('AUC : %0.2f' % roc_auc)  #AUC\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train_base, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train_logistic_result = logreg.predict_proba(x_train_base)\n",
    "\n",
    "predict_train_logistic = predict_train_logistic_result[:, 1]\n",
    "\n",
    "logreg_test_y_predicted = logreg.predict_proba(x_test_base)\n",
    "\n",
    "log_y_score = logreg_test_y_predicted[:, 1]\n",
    "\n",
    "predict_test=[]\n",
    "for i in range(log_y_score.shape[0]): \n",
    "    if log_y_score[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "#print(predict_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score,recall_score,confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test,predict_test)\n",
    "\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "\n",
    "#print('Precision:',precision_score(y_test_1, predict_test))\n",
    "#print('Recall:', recall_score(y_test_1, predict_test))\n",
    "#print('f1-score: %f' % f1_score(y_test_1, predict_test))\n",
    "print('Accuracy: %f' % accuracy_score(y_test, predict_test))\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n",
    "\n",
    "pd.crosstab(y_test_log,predict_test,rownames=['label'],colnames=['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc  ###計算roc和auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def roc_curve_and_score(y_test, pred_proba):\n",
    "    fpr, tpr, _ = roc_curve(y_test.ravel(), pred_proba.ravel())\n",
    "    roc_auc = roc_auc_score(y_test.ravel(), pred_proba.ravel())\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "#plt.grid()\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, log_y_score)\n",
    "plt.plot(fpr, tpr, color='#00db00', lw=2,\n",
    "         label='Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "plt.title('logistic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_train_logistic)\n",
    "print(predict_train_lstm)\n",
    "\n",
    "stacking=np.append(predict_train_logistic, predict_train_lstm)\n",
    "x_train_stacking=np.array(stacking).reshape(x_train_lstm.shape[0],2, order='F') #轉維\n",
    "\n",
    "from sklearn import  svm, preprocessing, metrics \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "svm_stacking = svm.SVC(kernel='linear',probability=True)\n",
    "svm_stacking.fit(x_train_stacking,y_train)\n",
    "\n",
    "print(x_train_stacking.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(log_y_score.shape)#logistic test 機率\n",
    "print(y_pred.shape)#lstm test 機率 \n",
    "print(y_score.shape)#Rf test 機率\n",
    "\n",
    "stacking_test=np.append(y_pred, log_y_score)\n",
    "x_test_stacking=np.array(stacking_test).reshape(total_test,2, order='F') #轉維\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=svm_stacking.predict(x_test_stacking)\n",
    "predict_pro_stacking=svm_stacking.predict_proba(x_test_stacking)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, predict)\n",
    "precision  = metrics.precision_score(y_test, predict)\n",
    "\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict,rownames=['label'],colnames=['predict'])\n",
    "predict_pro_stacking=predict_pro_stacking[:,1:2]\n",
    "\n",
    "#################92個test ca 輸出#####################\n",
    "#test=pd.DataFrame(predict[4689:])\n",
    "#test.to_csv('24hour_ca.csv', index=False)\n",
    "####################################### predict_pro_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_stacking=[]\n",
    "for i in range(predict_pro_stacking.shape[0]): \n",
    "    if predict_pro_stacking[i]>0.5:\n",
    "        predict_test_stacking.append(1)\n",
    "    else:\n",
    "        predict_test_stacking.append(0)\n",
    "predict_test_stacking = np.array(predict_test_stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(y_test_1D,predict_test,rownames=['label'],colnames=['predict'])  \n",
    "\n",
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_stacking)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[0,1])  \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n",
    "flag=0\n",
    "total_predict=0\n",
    "for i in range(y_pred.shape[0]): \n",
    "      if predict_pro_stacking[i]>0.5:\n",
    "            total_predict=total_predict+predict_pro_stacking[i]\n",
    "            flag=flag+1\n",
    "print(flag)  #score\n",
    "\n",
    "print(y_test_1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_stacking.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_test, predict_pro_stacking) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('stacking LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy : %0.2f' %accuracy)  #Accuracy\n",
    "print('precision : %0.2f' %precision)  #precision\n",
    "print('AUC : %0.2f' % roc_auc)  #AUC\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n",
    "#print('f1_score :%0.2f' %test_f1_score)  #f1_score\n",
    "print(total_predict/flag*100)  #score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_stacking)  #y_test # y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc  ###計算roc和auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics,ensemble\n",
    "from sklearn import model_selection\n",
    "\n",
    "gbm = xgb.XGBRegressor()\n",
    "\n",
    "xgb_params = {\n",
    "'learning_rate': [0.1,0.2,0.5],\n",
    "'n_estimators': [30,50,100],\n",
    "'max_depth': [5,10,20],\n",
    " 'alpha': [0.4,0.6],\n",
    " }\n",
    "\n",
    "xg_reg = model_selection.GridSearchCV(gbm, xgb_params, cv=5)\n",
    "xg_reg.fit(x_train_stacking,y_train)\n",
    "\n",
    "y_pred_xgb = xg_reg.predict(x_test_stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_xgb=[]\n",
    "for i in range(y_pred_xgb.shape[0]): \n",
    "    if y_pred_xgb[i]>0.5:\n",
    "        predict_test_xgb.append(1)\n",
    "    else:\n",
    "        predict_test_xgb.append(0)\n",
    "predict_test_xgb = np.array(predict_test_xgb)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_xgb,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n",
    "\n",
    "accuracy=(cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,0]+cm1[1,1])\n",
    "print('accuracy :%0.2f' % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics,ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "forest_stacking = ensemble.RandomForestClassifier()\n",
    "\n",
    "rf_params = {\n",
    "'n_estimators': [15,20,25],\n",
    "'max_depth': [4,5,6,7]\n",
    "#'n_estimators': [5],\n",
    "#'max_depth': [5]\n",
    " }\n",
    "\n",
    "forest_stacking = model_selection.GridSearchCV(forest_stacking, rf_params, cv=5)\n",
    "forest_fit=forest_stacking.fit(x_train_stacking,y_train)\n",
    "\n",
    "prob_predict_y_validation_stacking = forest_stacking.predict_proba(x_test_stacking)#给出带有概率值的结果，每个点所有label的概率和为1\n",
    "y_score_stacking = prob_predict_y_validation_stacking[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test=[]\n",
    "for i in range(y_score_stacking.shape[0]): \n",
    "    if y_score_stacking[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "\n",
    "accuracy=(cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,0]+cm1[1,1])\n",
    "\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n",
    "\n",
    "fpr,tpr,roc_auc = roc_curve_and_score(y_test, y_score_stacking) ###計算真正率和假正率\n",
    "\n",
    "print('AUC : %0.2f' % roc_auc)  #AUC\n",
    "\n",
    "print('accuracy :%0.2f' % accuracy)\n",
    "\n",
    "print(forest_stacking.best_params_)\n",
    "print(forest_stacking.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh.fit(x_train_stacking, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nei_test_y_predicted = neigh.predict(x_test_stacking)\n",
    "predict_test=[]\n",
    "for i in range(nei_test_y_predicted.shape[0]): \n",
    "    if nei_test_y_predicted[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "#print(predict_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score,recall_score,confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test)\n",
    "\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "\n",
    "#print('Precision:',precision_score(y_test_1, predict_test))\n",
    "#print('Recall:', recall_score(y_test_1, predict_test))\n",
    "#print('f1-score: %f' % f1_score(y_test_1, predict_test))\n",
    "print('Accuracy: %f' % accuracy_score(y_test, predict_test))\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test,rownames=['label'],colnames=['predict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "logreg_stacking = LogisticRegression()\n",
    "logreg_stacking.fit(x_train_stacking, y_train)\n",
    "#log_test_y_predicted = logreg.fit(x_train_stacking, y_train).decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_test_y_predicted_pro = logreg_stacking.predict_proba(x_test_stacking)\n",
    "\n",
    "log_score = logreg_test_y_predicted_pro[:, 1]\n",
    "\n",
    "predict_test_lr=[]\n",
    "for i in range(log_score.shape[0]): \n",
    "    if log_score[i]>0.5:\n",
    "        predict_test_lr.append(1)\n",
    "    else:\n",
    "        predict_test_lr.append(0)\n",
    "predict_test_lr = np.array(predict_test_lr)\n",
    "\n",
    "#print(predict_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score,recall_score,confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_lr)\n",
    "\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "\n",
    "#print('Precision:',precision_score(y_test_1, predict_test))\n",
    "#print('Recall:', recall_score(y_test_1, predict_test))\n",
    "#print('f1-score: %f' % f1_score(y_test_1, predict_test))\n",
    "print('Accuracy: %f' % accuracy_score(y_test, predict_test_lr))\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_lr,rownames=['label'],colnames=['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc  ###計算roc和auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "#plt.grid()\n",
    "\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, log_score)\n",
    "plt.plot(fpr, tpr, color='gray', lw=2,\n",
    "         label='Logistic Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_xgb)\n",
    "plt.plot(fpr, tpr, color='#00db00', lw=2,\n",
    "         label='XGBoost Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_score_stacking)\n",
    "plt.plot(fpr, tpr, color='#ff00ff', lw=2,\n",
    "         label='Random Forest Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, nei_test_y_predicted)\n",
    "plt.plot(fpr, tpr, color='red', lw=2,\n",
    "         label='Nearest Neighbors Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, predict_pro_stacking)\n",
    "plt.plot(fpr, tpr, color='blue', lw=2,\n",
    "         label='SVM Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "plt.title('Multi-Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_cxr=pd.read_csv(\"neur_test_all_patients_ca1.csv\")\n",
    "y_predict_cxr=predict_cxr[['predict']].values\n",
    "\n",
    "y_predict_combine=[]\n",
    "\n",
    "#print(predict_pro_stacking)\n",
    "#print(predict_pro_stacking.size)\n",
    "\n",
    "\n",
    "for idx, i in enumerate(predict_pro_stacking):\n",
    "    if y_predict_cxr[idx]==-1:          \n",
    "        y_predict_combine.append(predict_pro_stacking[idx])\n",
    "    else:\n",
    "        y_predict_combine.append((predict_pro_stacking[idx]+y_predict_cxr[idx])/2)\n",
    "        \n",
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "y_predict_combine=np.array(y_predict_combine)\n",
    "print(y_predict_combine.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_combine=[]\n",
    "for i in range(y_predict_combine.shape[0]): \n",
    "    if y_predict_combine[i]>0.5:\n",
    "        predict_test_combine.append(1)\n",
    "    else:\n",
    "        predict_test_combine.append(0)\n",
    "predict_test_combine = np.array(predict_test_combine)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_combine,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_combine)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "accuracy=(cm1[0,0]+cm1[1,1])/(cm1[1,1]+cm1[0,0]+cm1[0,1]+cm1[1,0])\n",
    "\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "\n",
    "print('accuracy : %0.2f' % accuracy)\n",
    "\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,threshold = roc_curve(y_test, y_predict_combine) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('SVM_stacking LSTM with cxr')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_cxr=pd.read_csv(\"neur_test_all_patients_ca1.csv\")\n",
    "y_predict_cxr=predict_cxr[['predict']].values\n",
    "\n",
    "y_predict_combine_lr=[]\n",
    "\n",
    "for idx, i in enumerate(log_score):\n",
    "    if y_predict_cxr[idx]==-1:          \n",
    "        y_predict_combine_lr.append(log_score[idx])\n",
    "    else:\n",
    "        y_predict_combine_lr.append((log_score[idx]+y_predict_cxr[idx])/2)\n",
    "        \n",
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "y_predict_combine_lr=np.array(y_predict_combine_lr)\n",
    "print(y_predict_combine_lr.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_combine=[]\n",
    "for i in range(y_predict_combine_lr.shape[0]): \n",
    "    if y_predict_combine_lr[i]>0.5:\n",
    "        predict_test_combine.append(1)\n",
    "    else:\n",
    "        predict_test_combine.append(0)\n",
    "predict_test_combine = np.array(predict_test_combine)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_combine,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_combine)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "accuracy=(cm1[0,0]+cm1[1,1])/(cm1[1,1]+cm1[0,0]+cm1[0,1]+cm1[1,0])\n",
    "\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "\n",
    "print('accuracy : %0.2f' % accuracy)\n",
    "\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_combine=pd.read_csv(\"predict_combine.csv\")\n",
    "#y_predict_combine=predict_combine[['eventV3']].values  \n",
    "#print(y_predict_combine.shape)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_test, y_predict_combine_lr) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('LR_stacking LSTM with cxr')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "brier_score=brier_score_loss(y_test, predict_pro_stacking)\n",
    "print(brier_score)\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fop, mpv = calibration_curve(y_test, predict_pro_stacking)\n",
    "#plt.figure()\n",
    "#plt.figure(figsize=(10,10))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot model reliability\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Plots (Stacking by SVM)')\n",
    "plt.plot(mpv, fop, marker='.', label='Brier_score (%1.2f)' % brier_score)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "brier_score=brier_score_loss(y_test, log_score)\n",
    "print(brier_score)\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fop, mpv = calibration_curve(y_test, log_score)\n",
    "#plt.figure()\n",
    "#plt.figure(figsize=(10,10))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot model reliability\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Plots (Stacking by SVM)')\n",
    "plt.plot(mpv, fop, marker='.', label='Brier_score (%1.2f)' % brier_score)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eicu=pd.read_csv(\"cascontrol_f2.csv\")  #baseline \n",
    "\n",
    "y_validation=df_eicu['user']\n",
    "\n",
    "x_lstm_validation=eicu_cardiac_total[['vHR','vRR','vsbp','vdbp','vmbp','vspo2']].values \n",
    "\n",
    "#x_lstm_validation=minmax_scale.fit_transform(x_lstm_validation)  #規一化\n",
    "x_lstm_validation=np.array(x_lstm_validation).reshape(10665,T,var) #轉三維  total \n",
    "\n",
    "print(x_lstm_validation.shape)\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_1 ,test_acc_1, test_f1_score_1, test_precision_1 = model_1.evaluate(x_lstm_validation,y_validation,\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'test accuracy = {round(test_acc_1 * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc_1) * 10665)} out of {10665} examples')\n",
    "\n",
    "validation_pred1= model_1.predict(x_lstm_validation)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation, validation_pred1) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label=' LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_2 ,test_acc_2, test_f1_score_2, test_precision_2 = model_2.evaluate(x_lstm_validation,y_validation,\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'test accuracy = {round(test_acc_2 * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc_2) * 10665)} out of {10665} examples')\n",
    "\n",
    "validation_pred2= model_2.predict(x_lstm_validation)\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation, validation_pred2) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label=' LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_3 ,test_acc_3, test_f1_score_3, test_precision_3 = model_3.evaluate(x_lstm_validation,y_validation,\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'test accuracy = {round(test_acc_3 * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc_3) * 10665)} out of {10665} examples')\n",
    "\n",
    "validation_pred3= model_3.predict(x_lstm_validation)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation, validation_pred3) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label=' LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_4 ,test_acc_4, test_f1_score_4, test_precision_4 = model_4.evaluate(x_lstm_validation,y_validation,\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'test accuracy = {round(test_acc_4 * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc_4) * 10665)} out of {10665} examples')\n",
    "\n",
    "validation_pred4= model_4.predict(x_lstm_validation)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation, validation_pred4) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label=' LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_5 ,test_acc_5, test_f1_score_5, test_precision_5 = model_5.evaluate(x_lstm_validation,y_validation,\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'test accuracy = {round(test_acc_5 * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc_5) * 10665)} out of {10665} examples')\n",
    "\n",
    "validation_pred5= model_5.predict(x_lstm_validation)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation, validation_pred5) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label=' LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_temp=np.append(validation_pred1,validation_pred2)\n",
    "pred_temp=np.append(pred_temp,validation_pred3)\n",
    "pred_temp=np.append(pred_temp,validation_pred4)\n",
    "pred_temp=np.append(pred_temp,validation_pred5)\n",
    "\n",
    "validation_pred_old=np.array(pred_temp).reshape(10665,5, order='F') #轉維\n",
    "\n",
    "validation_pred_old= np.mean(validation_pred_old, axis=1)\n",
    " \n",
    "eicu_acc=(test_acc_1+test_acc_2+test_acc_3+test_acc_4+test_acc_5)/5\n",
    "eicu_precision=(test_precision_1+test_precision_2+test_precision_3+test_precision_4+test_precision_5)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation, validation_pred_old) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label=' LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation_1D=np.array(y_validation).reshape(10665)\n",
    "\n",
    "predict_test=[]\n",
    "for i in range(validation_pred_old.shape[0]): \n",
    "    if validation_pred_old[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "pd.crosstab(y_validation_1D,predict_test,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_validation_1D,predict_test)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eicu=pd.read_csv(\"cascontrol_f2.csv\")  #baseline \n",
    "\n",
    "df_eicu=df_eicu.drop(['patientunitstayid'],axis=1)\n",
    "df_eicu=df_eicu.drop(['patienthealthsystemstayid'],axis=1)\n",
    "df_eicu=df_eicu.drop(['uniquepid'],axis=1)\n",
    "df_eicu=df_eicu.drop(['CA'],axis=1)\n",
    "df_eicu=df_eicu.drop(['hDied'],axis=1)\n",
    "\n",
    "df_eicu=df_eicu.drop(['BMI'],axis=1)\n",
    "df_eicu=df_eicu.drop(['ccscore'],axis=1)\n",
    "\n",
    "#df_eicu=pd.get_dummies(data=df_eicu,columns=[\"first_careunit\",\"ethnicity\",\"BMI\"])\n",
    "df_eicu=pd.get_dummies(data=df_eicu,columns=[\"first_careunit\",\"ethnicity\"])\n",
    "\n",
    "y_validation_old=df_eicu['user']\n",
    "df_eicu=df_eicu.drop(['user'],axis=1)\n",
    "x_validation_old=df_eicu.values\n",
    "\n",
    "minmax_scale =preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "x_validation_old=minmax_scale.fit_transform(x_validation_old)\n",
    "\n",
    "#predict_validation = forest.predict_proba(x_validation)#给出带有概率值的结果，每个点所有label的概率和为1\n",
    "#y_score_validation_old = predict_validation[:, 1] #RF\n",
    "\n",
    "predict_validation_old = logreg.predict_proba(x_validation_old)\n",
    "y_score_validation_old = predict_validation_old[:, 1]\n",
    "\n",
    "predict_test=[]\n",
    "for i in range(y_score_validation_old.shape[0]): \n",
    "    if y_score_validation_old[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "y_test_1D=np.array(y_validation_old).reshape(10665)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_validation_test=np.append(validation_pred_old, y_score_validation_old)\n",
    "x_validation_stacking=np.array(stacking_validation_test).reshape(10665,2, order='F') #轉維\n",
    "\n",
    "predict=svm_stacking.predict(x_validation_stacking)\n",
    "predict_pro_old=svm_stacking.predict_proba(x_validation_stacking)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_validation_old, predict)\n",
    "precision  = metrics.precision_score(y_validation_old, predict)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict,rownames=['label'],colnames=['predict'])\n",
    "predict_pro_old=predict_pro_old[:,1:2]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation_old, predict_pro_old) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation Eicu (SVM)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "predict_pro_old =pd.DataFrame(predict_pro_old)\n",
    "#predict_pro_old.to_csv('predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lr=logreg_stacking.predict(x_validation_stacking)\n",
    "predict_pro_old_lr=logreg_stacking.predict_proba(x_validation_stacking)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_validation_old, predict_lr)\n",
    "precision  = metrics.precision_score(y_validation_old, predict_lr)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_lr,rownames=['label'],colnames=['predict'])\n",
    "predict_pro_old_lr=predict_pro_old_lr[:,1:2]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_lr)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation_old, predict_pro_old_lr) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation Eicu (SVM)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "predict_pro_old_lr =pd.DataFrame(predict_pro_old_lr)\n",
    "#predict_pro_old.to_csv('predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_avg=pd.DataFrame(x_test_stacking)\n",
    "#test_avg.to_csv('test_avg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_pro_stacking_pri=pd.DataFrame(predict_pro_stacking)\n",
    "#predict_pro_stacking_pri.to_csv('predict_pro_stacking_pri.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
