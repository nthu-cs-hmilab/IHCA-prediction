{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 44536800 into shape (24100,1824)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2a849b90acce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[0mtrain_cardiac_total\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_cardiac_total\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m \u001b[0mtrain_cardiac_total\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_cardiac_total\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#轉二維  array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[0mtrain_cardiac_total\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_cardiac_total\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 44536800 into shape (24100,1824)"
     ]
    }
   ],
   "source": [
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(0)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(2)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(24)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(26)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "#from keras import backend as K\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "\n",
    "from sklearn import preprocessing  #用來標準化刻度\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import logcosh, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Import Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from time import time\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "####################################################################################  x_lstm_validation\n",
    "\n",
    "T=24\n",
    "\n",
    "train_cardiac_total=pd.read_csv(\"mimic_dead_vital_sign_combine_train_\"+str(T)+\"hours.csv\")\n",
    "test_cardiac_total=pd.read_csv(\"mimic_dead_vital_sign_combine_train_\"+str(T)+\"hours.csv\")\n",
    "train_cardiac_base_total=pd.read_csv(\"mimic_dead_baseline_total_v2.csv\")\n",
    "\n",
    "total_train=24100 #control+event\n",
    "total_test=6025 #control+event\n",
    "train_control=21160 #control\n",
    "\n",
    "var=76\n",
    "random=32\n",
    "smote_ratio=1\n",
    "near_ratio=1\n",
    "EPOCH = 3                    # number of epochs\n",
    "BATCH = 32                      # batch size\n",
    "\n",
    "dropout=0.4\n",
    "LR = 0.001                           # learning rate of the gradient descent\n",
    "LAMBD = 0.001                       # lambda in L2 regularizaion\n",
    "\n",
    "#####################################################################################\n",
    "train_cardiac_total=train_cardiac_total.drop(['subject_id'],axis=1)\n",
    "train_cardiac_total=train_cardiac_total.drop(['stay_id'],axis=1)\n",
    "train_cardiac_total=train_cardiac_total.drop(['indextime'],axis=1)\n",
    "train_cardiac_total=train_cardiac_total.drop(['date'],axis=1)\n",
    "train_cardiac_total=train_cardiac_total.drop(['hours_diff'],axis=1)\n",
    "train_cardiac_total=train_cardiac_total.drop(['event'],axis=1)\n",
    "\n",
    "test_cardiac_total=test_cardiac_total.drop(['subject_id'],axis=1)\n",
    "test_cardiac_total=test_cardiac_total.drop(['stay_id'],axis=1)\n",
    "test_cardiac_total=test_cardiac_total.drop(['indextime'],axis=1)\n",
    "test_cardiac_total=test_cardiac_total.drop(['date'],axis=1)\n",
    "test_cardiac_total=test_cardiac_total.drop(['hours_diff'],axis=1)\n",
    "test_cardiac_total=test_cardiac_total.drop(['event'],axis=1)\n",
    "\n",
    "#train_cardiac_total=train_cardiac_total.drop(['hadm_id'],axis=1)\n",
    "#train_cardiac_total=train_cardiac_total.drop(['stay_id'],axis=1)\n",
    "#train_cardiac_total=train_cardiac_total.drop(['los'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['CA'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['hospDIED'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['cardR'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['DNR'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['CMO'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['DNRDNI'],axis=1)\n",
    "\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['DNI'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['FullCode'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['indextime'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['ccs9'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['ccs10'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['cardRv2'],axis=1)\n",
    "\n",
    "###############CXR##############\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Atelectasis'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Cardiomegaly'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Consolidation'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Edema'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Enlarged Cardiomediastinum'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Fracture'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Lung Lesion'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Lung Opacity'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['No Finding'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Pleural Effusion'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Pleural Other'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Pneumonia'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Pneumothorax'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Support Devices'],axis=1)\n",
    "###############CXR##############\n",
    "\n",
    "#train_cardiac_base_total=pd.get_dummies(data=train_cardiac_base_total,columns=[\"first_careunit\",\"ethnicity\",\"BMI\"])\n",
    "train_cardiac_total=pd.get_dummies(data=train_cardiac_total,columns=[\"first_careunit\",\"ethnicity\"])\n",
    "test_cardiac_total=pd.get_dummies(data=test_cardiac_total,columns=[\"first_careunit\",\"ethnicity\"])\n",
    "\n",
    "\n",
    "####################################################################\n",
    "df_train_base=train_cardiac_base_total[:total_train]\n",
    "y_train=df_train_base[['eventV3']].values   #取train_labels\n",
    "df_test_base=train_cardiac_base_total[total_train:]\n",
    "y_test=df_test_base[['eventV3']].values   #取test_labels\n",
    "\n",
    "#x_train_base=train_features\n",
    "#x_test_base=test_features\n",
    "\n",
    "sm = SMOTE(random_state=random, sampling_strategy=smote_ratio)\n",
    "nr = NearMiss(sampling_strategy=near_ratio) \n",
    "\n",
    "#x_train_base, y_train_base = sm.fit_sample(x_train_base, y_train_base.ravel())\n",
    "#x_train_base, y_train_base = nr.fit_sample(x_train_base, y_train_base.ravel())\n",
    "\n",
    "#train_cardiac_total=train_cardiac_total.drop(['eventV3'],axis=1)\n",
    "\n",
    "train_cardiac_total=train_cardiac_total.values  \n",
    "train_cardiac_total=np.array(train_cardiac_total).reshape(total_train,T*var) #轉二維  array\n",
    "train_cardiac_total= pd.DataFrame(train_cardiac_total)\n",
    "\n",
    "x_test_lstm=test_cardiac_total.values \n",
    "#x_test_lstm=minmax_scale.fit_transform(x_test_lstm)  #規一化\n",
    "x_test_lstm=np.array(x_test_lstm).reshape(total_test,T,var) \n",
    "\n",
    "x_train_lstm, y_train = sm.fit_sample(train_cardiac_total, y_train.ravel())\n",
    "\n",
    "#x_train_lstm=minmax_scale.fit_transform(x_train_lstm)  #規一化\n",
    "\n",
    "x_train_lstm=np.array(x_train_lstm).reshape(x_train_lstm.shape[0],T,var) #轉三維  total\n",
    "\n",
    "#x_train_lstm_nr=np.array(x_train_lstm_nr).reshape(x_train_lstm_nr.shape[0],T,var) #轉三維  total\n",
    "\n",
    "#x_train_lstm_no_smote=np.array(train_cardiac_total).reshape(train_cardiac_total.shape[0],T,var) #轉三維  total\n",
    "\n",
    "print('timeline:',train_cardiac_total.shape)\n",
    "print('timeline:',x_train_lstm.shape)\n",
    "print('label:',y_train.shape)\n",
    "\n",
    "print('timeline:',x_test_lstm.shape)\n",
    "print('label:',y_test.shape)\n",
    "\n",
    "#print('timeline_no_smote:',x_train_lstm_no_smote.shape)\n",
    "#print('label_no_smote:',y_train_no_smote.shape)\n",
    "\n",
    "#print('timeline_nr:',x_train_lstm_nr.shape)\n",
    "#print('label_nr:',y_train_nr.shape)\n",
    "#print(df_train_base.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42320, 24, 76)\n",
      "(42320,)\n",
      "layers=[8, 8, 8, 1], train_examples=42320, test_examples=5384\n",
      "batch = 32, timesteps = 24, features = 76, epochs = 3\n",
      "lr = 0.001, lambda = 0.001, dropout = 1, recurr_dropout = 1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 24, 8)             2720      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 24, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,913\n",
      "Trainable params: 3,865\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 33856 samples, validate on 8464 samples\n",
      "Epoch 1/3\n",
      " - 33s - loss: 0.5334 - accuracy: 0.7777 - f1_m: 0.6611 - precision_m: 0.7728 - val_loss: 0.5615 - val_accuracy: 0.7785 - val_f1_m: 0.8734 - val_precision_m: 1.0000\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,val_f1_m,val_precision_m,loss,accuracy,f1_m,precision_m,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 31s - loss: 0.3873 - accuracy: 0.8413 - f1_m: 0.7818 - precision_m: 0.8005 - val_loss: 1.2666 - val_accuracy: 0.2811 - val_f1_m: 0.4321 - val_precision_m: 1.0000\n",
      "Epoch 3/3\n",
      " - 29s - loss: 0.3627 - accuracy: 0.8535 - f1_m: 0.8002 - precision_m: 0.8120 - val_loss: 0.8050 - val_accuracy: 0.5152 - val_f1_m: 0.6744 - val_precision_m: 1.0000\n",
      "-----------------------------------------------------------------\n",
      "Training was completed in 95.88 secs\n",
      "-----------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "train accuracy = 74.7117%\n",
      "test accuracy = 97.3626%\n",
      "test error = 142 out of 5384 examples\n"
     ]
    }
   ],
   "source": [
    "print(x_train_lstm.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm.shape[0]           # number of training examples (2D)\n",
    "#M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_smote = Sequential()\n",
    "\n",
    "model_smote.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_smote.add(Dropout(dropout))\n",
    "model_smote.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_smote.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_smote.add(Dropout(dropout))\n",
    "model_smote.add(BatchNormalization())\n",
    "\n",
    "model_smote.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_smote.add(Dropout(dropout))\n",
    "model_smote.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_smote.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_smote.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_smote.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_smote.fit(x_train_lstm, y_train,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0.2,\n",
    "                    #validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_smote.evaluate(x_train_lstm, y_train,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_smote.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_smote= model_smote.predict(x_test_lstm)\n",
    "\n",
    "predict_test_smote=[]\n",
    "for i in range(y_pred_smote.shape[0]): \n",
    "    if y_pred_smote[i]>0.5:\n",
    "        predict_test_smote.append(1)\n",
    "    else:\n",
    "        predict_test_smote.append(0)\n",
    "predict_test_smote = np.array(predict_test_smote)\n",
    "print(predict_test_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[5198   91]\n",
      " [  51   44]]\n",
      "accuracy: 0.9736255572065379\n",
      "specificity: 0.9827944791075818\n",
      "sensitivity: 0.4631578947368421\n",
      "ppv: 0.32592592592592595\n",
      "npv: 0.9902838635930653\n"
     ]
    }
   ],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_smote,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_smote)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "accuracy= (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,1]+cm1[1,0])   #FPR\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('accuracy:',accuracy)\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_test, y_pred_smote) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('smote')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33856, 24, 76)\n",
      "(8464, 24, 76)\n",
      "(33856,)\n",
      "(8464,)\n",
      "layers=[8, 8, 8, 1], train_examples=33856, test_examples=5384\n",
      "batch = 32, timesteps = 24, features = 76, epochs = 3\n",
      "lr = 0.001, lambda = 0.001, dropout = 1, recurr_dropout = 1\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 24, 8)             2720      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 24, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,913\n",
      "Trainable params: 3,865\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 33856 samples, validate on 8464 samples\n",
      "Epoch 1/3\n",
      " - 32s - loss: 0.7015 - accuracy: 0.5812 - f1_m: 0.5099 - precision_m: 0.6447 - val_loss: 0.5898 - val_accuracy: 0.6931 - val_f1_m: 0.3084 - val_precision_m: 0.5019\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,val_f1_m,val_precision_m,loss,accuracy,f1_m,precision_m,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 31s - loss: 0.6172 - accuracy: 0.6691 - f1_m: 0.5687 - precision_m: 0.8167 - val_loss: 0.5566 - val_accuracy: 0.7200 - val_f1_m: 0.3217 - val_precision_m: 0.5019\n",
      "Epoch 3/3\n",
      " - 31s - loss: 0.5756 - accuracy: 0.7180 - f1_m: 0.6466 - precision_m: 0.8460 - val_loss: 0.5091 - val_accuracy: 0.7753 - val_f1_m: 0.4089 - val_precision_m: 0.5015\n",
      "-----------------------------------------------------------------\n",
      "Training was completed in 96.96 secs\n",
      "-----------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "train accuracy = 77.5579%\n",
      "test accuracy = 85.4198%\n",
      "test error = 785 out of 5384 examples\n"
     ]
    }
   ],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo1\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[part_0:], x_event_1[part_1:]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[:part_0], x_event_1[:part_1]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[part_0:], y_event_1[part_1:]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[:part_0], y_event_1[:part_1]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_1.add(Dropout(dropout))\n",
    "model_1.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_1.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_1.add(Dropout(dropout))\n",
    "model_1.add(BatchNormalization())\n",
    "\n",
    "model_1.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_1.add(Dropout(dropout))\n",
    "model_1.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_1.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_1.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_1.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_1.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_1.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_1.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred1= model_1.predict(x_test_lstm)\n",
    "predict_train_lstm1=model_1.predict(x_train_lstm)\n",
    "\n",
    "test_acc_1=test_acc\n",
    "test_precision_1=test_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "predict_test_1=[]\n",
    "for i in range(y_pred1.shape[0]): \n",
    "    if y_pred1[i]>0.5:\n",
    "        predict_test_1.append(1)\n",
    "    else:\n",
    "        predict_test_1.append(0)\n",
    "predict_test_1 = np.array(predict_test_1)\n",
    "print(predict_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[4536  753]\n",
      " [  32   63]]\n",
      "specificity: 0.8576290414066932\n",
      "sensitivity: 0.6631578947368421\n",
      "ppv: 0.07720588235294118\n",
      "npv: 0.9929947460595446\n"
     ]
    }
   ],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_1,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_1)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33856, 24, 76)\n",
      "(8464, 24, 76)\n",
      "(33856,)\n",
      "(8464,)\n",
      "layers=[8, 8, 8, 1], train_examples=33856, test_examples=5384\n",
      "batch = 32, timesteps = 24, features = 76, epochs = 3\n",
      "lr = 0.001, lambda = 0.001, dropout = 1, recurr_dropout = 1\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 24, 8)             2720      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 24, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,913\n",
      "Trainable params: 3,865\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 33856 samples, validate on 8464 samples\n",
      "Epoch 1/3\n",
      " - 34s - loss: 0.5978 - accuracy: 0.7253 - f1_m: 0.7153 - precision_m: 0.7418 - val_loss: 0.4342 - val_accuracy: 0.8248 - val_f1_m: 0.4747 - val_precision_m: 0.5017\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,val_f1_m,val_precision_m,loss,accuracy,f1_m,precision_m,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 32s - loss: 0.4261 - accuracy: 0.8355 - f1_m: 0.8351 - precision_m: 0.8283 - val_loss: 0.3439 - val_accuracy: 0.8644 - val_f1_m: 0.4713 - val_precision_m: 0.5017\n",
      "Epoch 3/3\n",
      " - 32s - loss: 0.3908 - accuracy: 0.8456 - f1_m: 0.8468 - precision_m: 0.8320 - val_loss: 0.3494 - val_accuracy: 0.8593 - val_f1_m: 0.4872 - val_precision_m: 0.5017\n",
      "-----------------------------------------------------------------\n",
      "Training was completed in 100.91 secs\n",
      "-----------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "train accuracy = 86.1974%\n",
      "test accuracy = 77.0245%\n",
      "test error = 1237 out of 5384 examples\n"
     ]
    }
   ],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo2\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[:part_0], x_event_1[:part_1],x_event_0[2*part_0:],x_event_1[2*part_1:]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[part_0:2*part_0], x_event_1[part_1:2*part_1]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[:part_0], y_event_1[:part_1],y_event_0[2*part_0:], y_event_1[2*part_1:]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[part_0:2*part_0], y_event_1[part_1:2*part_1]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "             #  dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_2.add(Dropout(dropout))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_2.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "             #  dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_2.add(Dropout(dropout))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_2.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_2.add(Dropout(dropout))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_2.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_2.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_2.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_2.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_2.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_2.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred2= model_2.predict(x_test_lstm)\n",
    "predict_train_lstm2=model_2.predict(x_train_lstm)\n",
    "\n",
    "test_acc_2=test_acc\n",
    "test_precision_2=test_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predict_test_2=[]\n",
    "for i in range(y_pred2.shape[0]): \n",
    "    if y_pred2[i]>0.5:\n",
    "        predict_test_2.append(1)\n",
    "    else:\n",
    "        predict_test_2.append(0)\n",
    "predict_test_2 = np.array(predict_test_2)\n",
    "print(predict_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[4065 1224]\n",
      " [  13   82]]\n",
      "specificity: 0.7685762904140669\n",
      "sensitivity: 0.8631578947368421\n",
      "ppv: 0.06278713629402756\n",
      "npv: 0.9968121628249141\n"
     ]
    }
   ],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_2,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_2)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])   \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33856, 24, 76)\n",
      "(8464, 24, 76)\n",
      "(33856,)\n",
      "(8464,)\n",
      "layers=[8, 8, 8, 1], train_examples=33856, test_examples=5384\n",
      "batch = 32, timesteps = 24, features = 76, epochs = 3\n",
      "lr = 0.001, lambda = 0.001, dropout = 1, recurr_dropout = 1\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 24, 8)             2720      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 24, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,913\n",
      "Trainable params: 3,865\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 33856 samples, validate on 8464 samples\n",
      "Epoch 1/3\n",
      " - 33s - loss: 0.5866 - accuracy: 0.7295 - f1_m: 0.6983 - precision_m: 0.7847 - val_loss: 0.4678 - val_accuracy: 0.8013 - val_f1_m: 0.4187 - val_precision_m: 0.5017\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,val_f1_m,val_precision_m,loss,accuracy,f1_m,precision_m,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 31s - loss: 0.4526 - accuracy: 0.8084 - f1_m: 0.8027 - precision_m: 0.8215 - val_loss: 0.4576 - val_accuracy: 0.8006 - val_f1_m: 0.4958 - val_precision_m: 0.5014\n",
      "Epoch 3/3\n",
      " - 31s - loss: 0.4057 - accuracy: 0.8345 - f1_m: 0.8355 - precision_m: 0.8223 - val_loss: 0.4199 - val_accuracy: 0.8253 - val_f1_m: 0.4848 - val_precision_m: 0.5016\n",
      "-----------------------------------------------------------------\n",
      "Training was completed in 98.30 secs\n",
      "-----------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "train accuracy = 82.2483%\n",
      "test accuracy = 71.4339%\n",
      "test error = 1538 out of 5384 examples\n"
     ]
    }
   ],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo3\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[:2*part_0], x_event_1[:2*part_1],x_event_0[3*part_0:],x_event_1[3*part_1:]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[2*part_0:3*part_0], x_event_1[2*part_1:3*part_1]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[:2*part_0], y_event_1[:2*part_1],y_event_0[3*part_0:], y_event_1[3*part_1:]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[2*part_0:3*part_0], y_event_1[2*part_1:3*part_1]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_3.add(Dropout(dropout))\n",
    "model_3.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_3.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "             #  dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_3.add(Dropout(dropout))\n",
    "model_3.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_3.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "             #  dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_3.add(Dropout(dropout))\n",
    "model_3.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_3.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_3.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_3.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_3.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_3.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_3.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred3= model_3.predict(x_test_lstm)\n",
    "predict_train_lstm3=model_3.predict(x_train_lstm)\n",
    "\n",
    "test_acc_3=test_acc\n",
    "test_precision_3=test_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predict_test_3=[]\n",
    "for i in range(y_pred3.shape[0]): \n",
    "    if y_pred3[i]>0.5:\n",
    "        predict_test_3.append(1)\n",
    "    else:\n",
    "        predict_test_3.append(0)\n",
    "predict_test_3 = np.array(predict_test_3)\n",
    "print(predict_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[3770 1519]\n",
      " [  19   76]]\n",
      "specificity: 0.7128001512573265\n",
      "sensitivity: 0.8\n",
      "ppv: 0.04764890282131661\n",
      "npv: 0.9949854842966482\n"
     ]
    }
   ],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_3,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_3)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33856, 24, 76)\n",
      "(8464, 24, 76)\n",
      "(33856,)\n",
      "(8464,)\n",
      "layers=[8, 8, 8, 1], train_examples=33856, test_examples=5384\n",
      "batch = 32, timesteps = 24, features = 76, epochs = 3\n",
      "lr = 0.001, lambda = 0.001, dropout = 1, recurr_dropout = 1\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 24, 8)             2720      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 24, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,913\n",
      "Trainable params: 3,865\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 33856 samples, validate on 8464 samples\n",
      "Epoch 1/3\n",
      " - 34s - loss: 0.6587 - accuracy: 0.6609 - f1_m: 0.6316 - precision_m: 0.6998 - val_loss: 0.5114 - val_accuracy: 0.7644 - val_f1_m: 0.3788 - val_precision_m: 0.5015\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,val_f1_m,val_precision_m,loss,accuracy,f1_m,precision_m,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 32s - loss: 0.5094 - accuracy: 0.7667 - f1_m: 0.7511 - precision_m: 0.8028 - val_loss: 0.4224 - val_accuracy: 0.8321 - val_f1_m: 0.4782 - val_precision_m: 0.5014\n",
      "Epoch 3/3\n",
      " - 32s - loss: 0.3985 - accuracy: 0.8383 - f1_m: 0.8387 - precision_m: 0.8274 - val_loss: 0.3422 - val_accuracy: 0.8587 - val_f1_m: 0.4531 - val_precision_m: 0.5017\n",
      "-----------------------------------------------------------------\n",
      "Training was completed in 99.75 secs\n",
      "-----------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "train accuracy = 86.2417%\n",
      "test accuracy = 88.7444%\n",
      "test error = 606 out of 5384 examples\n"
     ]
    }
   ],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo4\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[:3*part_0], x_event_1[:3*part_1],x_event_0[4*part_0:],x_event_1[4*part_1:]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[3*part_0:4*part_0], x_event_1[3*part_1:4*part_1]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[:3*part_0], y_event_1[:3*part_1],y_event_0[4*part_0:], y_event_1[4*part_1:]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[3*part_0:4*part_0], y_event_1[3*part_1:4*part_1]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_4 = Sequential()\n",
    "\n",
    "model_4.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_4.add(Dropout(dropout))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_4.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "            #   dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_4.add(Dropout(dropout))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_4.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "           #    dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_4.add(Dropout(dropout))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_4.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_4.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_4.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_4.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_4.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_4.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred4= model_4.predict(x_test_lstm)\n",
    "predict_train_lstm4=model_4.predict(x_train_lstm)\n",
    "\n",
    "test_acc_4=test_acc\n",
    "test_precision_4=test_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "predict_test_4=[]\n",
    "for i in range(y_pred4.shape[0]): \n",
    "    if y_pred4[i]>0.5:\n",
    "        predict_test_4.append(1)\n",
    "    else:\n",
    "        predict_test_4.append(0)\n",
    "predict_test_4 = np.array(predict_test_4)\n",
    "print(predict_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[4709  580]\n",
      " [  26   69]]\n",
      "specificity: 0.8903384382681037\n",
      "sensitivity: 0.7263157894736842\n",
      "ppv: 0.10631741140215717\n",
      "npv: 0.9945089757127772\n"
     ]
    }
   ],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_4,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_4)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])   \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33856, 24, 76)\n",
      "(8464, 24, 76)\n",
      "(33856,)\n",
      "(8464,)\n",
      "layers=[8, 8, 8, 1], train_examples=33856, test_examples=5384\n",
      "batch = 32, timesteps = 24, features = 76, epochs = 3\n",
      "lr = 0.001, lambda = 0.001, dropout = 1, recurr_dropout = 1\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 24, 8)             2720      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 24, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,913\n",
      "Trainable params: 3,865\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 33856 samples, validate on 8464 samples\n",
      "Epoch 1/3\n",
      " - 41s - loss: 0.5436 - accuracy: 0.7580 - f1_m: 0.7476 - precision_m: 0.7697 - val_loss: 0.4202 - val_accuracy: 0.8385 - val_f1_m: 0.4822 - val_precision_m: 0.5015\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,val_f1_m,val_precision_m,loss,accuracy,f1_m,precision_m,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 38s - loss: 0.4169 - accuracy: 0.8352 - f1_m: 0.8344 - precision_m: 0.8269 - val_loss: 0.3616 - val_accuracy: 0.8527 - val_f1_m: 0.4793 - val_precision_m: 0.5013\n",
      "Epoch 3/3\n",
      " - 36s - loss: 0.3806 - accuracy: 0.8450 - f1_m: 0.8461 - precision_m: 0.8305 - val_loss: 0.4079 - val_accuracy: 0.8086 - val_f1_m: 0.4902 - val_precision_m: 0.5012\n",
      "-----------------------------------------------------------------\n",
      "Training was completed in 118.08 secs\n",
      "-----------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "train accuracy = 80.6918%\n",
      "test accuracy = 65.3418%\n",
      "test error = 1866 out of 5384 examples\n"
     ]
    }
   ],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo5\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[:4*part_0], x_event_1[:4*part_1]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[4*part_0:], x_event_1[4*part_1:]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[:4*part_0], y_event_1[:4*part_1]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[4*part_0:], y_event_1[4*part_1:]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_5 = Sequential()\n",
    "\n",
    "model_5.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "            #   dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_5.add(Dropout(dropout))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_5.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "            #   dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_5.add(Dropout(dropout))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_5.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "           #    dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_5.add(Dropout(dropout))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_5.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_5.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_5.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_5.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_5.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_5.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred5= model_5.predict(x_test_lstm)\n",
    "predict_train_lstm5=model_5.predict(x_train_lstm)\n",
    "\n",
    "test_acc_5=test_acc\n",
    "test_precision_5=test_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predict_test_5=[]\n",
    "for i in range(y_pred5.shape[0]): \n",
    "    if y_pred5[i]>0.5:\n",
    "        predict_test_5.append(1)\n",
    "    else:\n",
    "        predict_test_5.append(0)\n",
    "predict_test_5 = np.array(predict_test_5)\n",
    "print(predict_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[3432 1857]\n",
      " [   9   86]]\n",
      "specificity: 0.6488939307997731\n",
      "sensitivity: 0.9052631578947369\n",
      "ppv: 0.0442614513638703\n",
      "npv: 0.997384481255449\n"
     ]
    }
   ],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_5,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_5)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_temp=np.append(y_pred1,y_pred2)\n",
    "y_pred_temp=np.append(y_pred_temp,y_pred3)\n",
    "y_pred_temp=np.append(y_pred_temp,y_pred4)\n",
    "y_pred_temp=np.append(y_pred_temp,y_pred5)\n",
    "\n",
    "predict_train_temp=np.append(predict_train_lstm1,predict_train_lstm2)\n",
    "predict_train_temp=np.append(predict_train_temp,predict_train_lstm3)\n",
    "predict_train_temp=np.append(predict_train_temp,predict_train_lstm4)\n",
    "predict_train_temp=np.append(predict_train_temp,predict_train_lstm5)\n",
    "\n",
    "y_pred=np.array(y_pred_temp).reshape(x_test_lstm.shape[0],5, order='F') #轉維\n",
    "predict_train_lstm=np.array(predict_train_temp).reshape(x_train_lstm.shape[0],5, order='F') #轉維\n",
    "\n",
    "y_pred= np.mean(y_pred, axis=1)\n",
    "predict_train_lstm= np.mean(predict_train_lstm, axis=1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predict_test=[]\n",
    "for i in range(y_pred.shape[0]): \n",
    "    if y_pred[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "print(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[4359  930]\n",
      " [  14   81]]\n",
      "specificity: 0.8241633579126489\n",
      "sensitivity: 0.8526315789473684\n",
      "ppv: 0.08011869436201781\n",
      "npv: 0.8241633579126489\n"
     ]
    }
   ],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "accuracy_5_fold=(cm1[0,0]+cm1[1,1])/(cm1[1,1]+cm1[0,0]+cm1[0,1]+cm1[1,0])\n",
    "\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[0,1])  \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n",
    "\n",
    "\n",
    "y_pred=np.array(y_pred).reshape(total_test)\n",
    "\n",
    "flag=0\n",
    "total_predict=0\n",
    "for i in range(y_pred.shape[0]): \n",
    "      if y_pred[i]>0.5:\n",
    "            total_predict=total_predict+y_pred[i]\n",
    "            flag=flag+1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_test, y_pred) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('5 fold LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.82\n",
      "AUC : 0.90\n",
      "Sensitivity : 0.85\n",
      "Specificity :0.82\n",
      "65.79930518784226\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : %0.2f' %accuracy_5_fold)  #accuracy\n",
    "print('AUC : %0.2f' % roc_auc)  #AUC\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n",
    "#print('f1_score :%0.2f' %test_f1_score)  #f1_score\n",
    "print(total_predict/flag*100)  #score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
