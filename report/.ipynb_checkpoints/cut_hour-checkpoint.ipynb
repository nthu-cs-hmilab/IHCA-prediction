{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452340, 12)\n",
      "(113064, 12)\n",
      "452340\n",
      "113064\n",
      "(506100, 12)\n",
      "(126525, 12)\n",
      "506100\n",
      "126525\n",
      "(430800, 12)\n",
      "(107680, 12)\n",
      "430800\n",
      "107680\n",
      "(482000, 12)\n",
      "(120500, 12)\n",
      "482000\n",
      "120500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "import seaborn as sns   # plotting heatmap\n",
    "\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing  #用來標準化刻度\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import logcosh, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "time=21\n",
    "to_time=time-1\n",
    "\n",
    "df_ca_train=pd.read_csv(\"mimic_ca_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_ca_test=pd.read_csv(\"mimic_ca_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "df_dead_train=pd.read_csv(\"mimic_dead_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_dead_test=pd.read_csv(\"mimic_dead_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "#######################殺資料###############################\n",
    "flag_ca_train=df_ca_train.shape[0] \n",
    "flag_ca_test=df_ca_test.shape[0]  \n",
    "\n",
    "flag_dead_train=df_dead_train.shape[0] \n",
    "flag_dead_test=df_dead_test.shape[0] \n",
    "\n",
    "for i in range(flag_ca_train): \n",
    "      if i%time== to_time: \n",
    "         df_ca_train=df_ca_train.drop([i])\n",
    "        \n",
    "for i in range(flag_ca_test): \n",
    "      if i%time== to_time: \n",
    "         df_ca_test=df_ca_test.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_train): \n",
    "      if i%time== to_time: \n",
    "         df_dead_train=df_dead_train.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_test): \n",
    "      if i%time== to_time: \n",
    "         df_dead_test=df_dead_test.drop([i])\n",
    "###########################################################\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "df_ca_train.to_csv('mimic_ca_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_ca_test.to_csv('mimic_ca_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_train.to_csv('mimic_dead_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_test.to_csv('mimic_dead_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430800, 12)\n",
      "(107680, 12)\n",
      "430800\n",
      "107680\n",
      "(482000, 12)\n",
      "(120500, 12)\n",
      "482000\n",
      "120500\n",
      "(409260, 12)\n",
      "(102296, 12)\n",
      "409260\n",
      "102296\n",
      "(457900, 12)\n",
      "(114475, 12)\n",
      "457900\n",
      "114475\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "import seaborn as sns   # plotting heatmap\n",
    "\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing  #用來標準化刻度\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import logcosh, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "time=20\n",
    "to_time=time-1\n",
    "\n",
    "df_ca_train=pd.read_csv(\"mimic_ca_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_ca_test=pd.read_csv(\"mimic_ca_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "df_dead_train=pd.read_csv(\"mimic_dead_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_dead_test=pd.read_csv(\"mimic_dead_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "#######################殺資料###############################\n",
    "flag_ca_train=df_ca_train.shape[0] \n",
    "flag_ca_test=df_ca_test.shape[0]  \n",
    "\n",
    "flag_dead_train=df_dead_train.shape[0] \n",
    "flag_dead_test=df_dead_test.shape[0] \n",
    "\n",
    "for i in range(flag_ca_train): \n",
    "      if i%time== to_time: \n",
    "         df_ca_train=df_ca_train.drop([i])\n",
    "        \n",
    "for i in range(flag_ca_test): \n",
    "      if i%time== to_time: \n",
    "         df_ca_test=df_ca_test.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_train): \n",
    "      if i%time== to_time: \n",
    "         df_dead_train=df_dead_train.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_test): \n",
    "      if i%time== to_time: \n",
    "         df_dead_test=df_dead_test.drop([i])\n",
    "###########################################################\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "df_ca_train.to_csv('mimic_ca_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_ca_test.to_csv('mimic_ca_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_train.to_csv('mimic_dead_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_test.to_csv('mimic_dead_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409260, 12)\n",
      "(102296, 12)\n",
      "409260\n",
      "102296\n",
      "(457900, 12)\n",
      "(114475, 12)\n",
      "457900\n",
      "114475\n",
      "(387720, 12)\n",
      "(96912, 12)\n",
      "387720\n",
      "96912\n",
      "(433800, 12)\n",
      "(108450, 12)\n",
      "433800\n",
      "108450\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "import seaborn as sns   # plotting heatmap\n",
    "\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing  #用來標準化刻度\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import logcosh, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "time=19\n",
    "to_time=time-1\n",
    "\n",
    "df_ca_train=pd.read_csv(\"mimic_ca_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_ca_test=pd.read_csv(\"mimic_ca_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "df_dead_train=pd.read_csv(\"mimic_dead_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_dead_test=pd.read_csv(\"mimic_dead_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "#######################殺資料###############################\n",
    "flag_ca_train=df_ca_train.shape[0] \n",
    "flag_ca_test=df_ca_test.shape[0]  \n",
    "\n",
    "flag_dead_train=df_dead_train.shape[0] \n",
    "flag_dead_test=df_dead_test.shape[0] \n",
    "\n",
    "for i in range(flag_ca_train): \n",
    "      if i%time== to_time: \n",
    "         df_ca_train=df_ca_train.drop([i])\n",
    "        \n",
    "for i in range(flag_ca_test): \n",
    "      if i%time== to_time: \n",
    "         df_ca_test=df_ca_test.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_train): \n",
    "      if i%time== to_time: \n",
    "         df_dead_train=df_dead_train.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_test): \n",
    "      if i%time== to_time: \n",
    "         df_dead_test=df_dead_test.drop([i])\n",
    "###########################################################\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "df_ca_train.to_csv('mimic_ca_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_ca_test.to_csv('mimic_ca_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_train.to_csv('mimic_dead_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_test.to_csv('mimic_dead_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387720, 12)\n",
      "(96912, 12)\n",
      "387720\n",
      "96912\n",
      "(433800, 12)\n",
      "(108450, 12)\n",
      "433800\n",
      "108450\n",
      "(366180, 12)\n",
      "(91528, 12)\n",
      "366180\n",
      "91528\n",
      "(409700, 12)\n",
      "(102425, 12)\n",
      "409700\n",
      "102425\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "import seaborn as sns   # plotting heatmap\n",
    "\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing  #用來標準化刻度\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import logcosh, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "time=18\n",
    "to_time=time-1\n",
    "\n",
    "df_ca_train=pd.read_csv(\"mimic_ca_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_ca_test=pd.read_csv(\"mimic_ca_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "df_dead_train=pd.read_csv(\"mimic_dead_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_dead_test=pd.read_csv(\"mimic_dead_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "#######################殺資料###############################\n",
    "flag_ca_train=df_ca_train.shape[0] \n",
    "flag_ca_test=df_ca_test.shape[0]  \n",
    "\n",
    "flag_dead_train=df_dead_train.shape[0] \n",
    "flag_dead_test=df_dead_test.shape[0] \n",
    "\n",
    "for i in range(flag_ca_train): \n",
    "      if i%time== to_time: \n",
    "         df_ca_train=df_ca_train.drop([i])\n",
    "        \n",
    "for i in range(flag_ca_test): \n",
    "      if i%time== to_time: \n",
    "         df_ca_test=df_ca_test.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_train): \n",
    "      if i%time== to_time: \n",
    "         df_dead_train=df_dead_train.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_test): \n",
    "      if i%time== to_time: \n",
    "         df_dead_test=df_dead_test.drop([i])\n",
    "###########################################################\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "df_ca_train.to_csv('mimic_ca_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_ca_test.to_csv('mimic_ca_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_train.to_csv('mimic_dead_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_test.to_csv('mimic_dead_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(366180, 12)\n",
      "(91528, 12)\n",
      "366180\n",
      "91528\n",
      "(409700, 12)\n",
      "(102425, 12)\n",
      "409700\n",
      "102425\n",
      "(344640, 12)\n",
      "(86144, 12)\n",
      "344640\n",
      "86144\n",
      "(385600, 12)\n",
      "(96400, 12)\n",
      "385600\n",
      "96400\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "import seaborn as sns   # plotting heatmap\n",
    "\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing  #用來標準化刻度\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import logcosh, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "time=17\n",
    "to_time=time-1\n",
    "\n",
    "df_ca_train=pd.read_csv(\"mimic_ca_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_ca_test=pd.read_csv(\"mimic_ca_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "df_dead_train=pd.read_csv(\"mimic_dead_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_dead_test=pd.read_csv(\"mimic_dead_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "#######################殺資料###############################\n",
    "flag_ca_train=df_ca_train.shape[0] \n",
    "flag_ca_test=df_ca_test.shape[0]  \n",
    "\n",
    "flag_dead_train=df_dead_train.shape[0] \n",
    "flag_dead_test=df_dead_test.shape[0] \n",
    "\n",
    "for i in range(flag_ca_train): \n",
    "      if i%time== to_time: \n",
    "         df_ca_train=df_ca_train.drop([i])\n",
    "        \n",
    "for i in range(flag_ca_test): \n",
    "      if i%time== to_time: \n",
    "         df_ca_test=df_ca_test.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_train): \n",
    "      if i%time== to_time: \n",
    "         df_dead_train=df_dead_train.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_test): \n",
    "      if i%time== to_time: \n",
    "         df_dead_test=df_dead_test.drop([i])\n",
    "###########################################################\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "df_ca_train.to_csv('mimic_ca_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_ca_test.to_csv('mimic_ca_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_train.to_csv('mimic_dead_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_test.to_csv('mimic_dead_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(344640, 12)\n",
      "(86144, 12)\n",
      "344640\n",
      "86144\n",
      "(385600, 12)\n",
      "(96400, 12)\n",
      "385600\n",
      "96400\n",
      "(323100, 12)\n",
      "(80760, 12)\n",
      "323100\n",
      "80760\n",
      "(361500, 12)\n",
      "(90375, 12)\n",
      "361500\n",
      "90375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "import seaborn as sns   # plotting heatmap\n",
    "\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing  #用來標準化刻度\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import logcosh, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "time=16\n",
    "to_time=time-1\n",
    "\n",
    "df_ca_train=pd.read_csv(\"mimic_ca_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_ca_test=pd.read_csv(\"mimic_ca_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "df_dead_train=pd.read_csv(\"mimic_dead_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_dead_test=pd.read_csv(\"mimic_dead_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "#######################殺資料###############################\n",
    "flag_ca_train=df_ca_train.shape[0] \n",
    "flag_ca_test=df_ca_test.shape[0]  \n",
    "\n",
    "flag_dead_train=df_dead_train.shape[0] \n",
    "flag_dead_test=df_dead_test.shape[0] \n",
    "\n",
    "for i in range(flag_ca_train): \n",
    "      if i%time== to_time: \n",
    "         df_ca_train=df_ca_train.drop([i])\n",
    "        \n",
    "for i in range(flag_ca_test): \n",
    "      if i%time== to_time: \n",
    "         df_ca_test=df_ca_test.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_train): \n",
    "      if i%time== to_time: \n",
    "         df_dead_train=df_dead_train.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_test): \n",
    "      if i%time== to_time: \n",
    "         df_dead_test=df_dead_test.drop([i])\n",
    "###########################################################\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "df_ca_train.to_csv('mimic_ca_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_ca_test.to_csv('mimic_ca_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_train.to_csv('mimic_dead_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_test.to_csv('mimic_dead_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323100, 12)\n",
      "(80760, 12)\n",
      "323100\n",
      "80760\n",
      "(361500, 12)\n",
      "(90375, 12)\n",
      "361500\n",
      "90375\n",
      "(301560, 12)\n",
      "(75376, 12)\n",
      "301560\n",
      "75376\n",
      "(337400, 12)\n",
      "(84350, 12)\n",
      "337400\n",
      "84350\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "import seaborn as sns   # plotting heatmap\n",
    "\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing  #用來標準化刻度\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import logcosh, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "time=15\n",
    "to_time=time-1\n",
    "\n",
    "df_ca_train=pd.read_csv(\"mimic_ca_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_ca_test=pd.read_csv(\"mimic_ca_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "df_dead_train=pd.read_csv(\"mimic_dead_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_dead_test=pd.read_csv(\"mimic_dead_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "#######################殺資料###############################\n",
    "flag_ca_train=df_ca_train.shape[0] \n",
    "flag_ca_test=df_ca_test.shape[0]  \n",
    "\n",
    "flag_dead_train=df_dead_train.shape[0] \n",
    "flag_dead_test=df_dead_test.shape[0] \n",
    "\n",
    "for i in range(flag_ca_train): \n",
    "      if i%time== to_time: \n",
    "         df_ca_train=df_ca_train.drop([i])\n",
    "        \n",
    "for i in range(flag_ca_test): \n",
    "      if i%time== to_time: \n",
    "         df_ca_test=df_ca_test.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_train): \n",
    "      if i%time== to_time: \n",
    "         df_dead_train=df_dead_train.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_test): \n",
    "      if i%time== to_time: \n",
    "         df_dead_test=df_dead_test.drop([i])\n",
    "###########################################################\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "df_ca_train.to_csv('mimic_ca_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_ca_test.to_csv('mimic_ca_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_train.to_csv('mimic_dead_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_test.to_csv('mimic_dead_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301560, 12)\n",
      "(75376, 12)\n",
      "301560\n",
      "75376\n",
      "(337400, 12)\n",
      "(84350, 12)\n",
      "337400\n",
      "84350\n",
      "(280020, 12)\n",
      "(69992, 12)\n",
      "280020\n",
      "69992\n",
      "(313300, 12)\n",
      "(78325, 12)\n",
      "313300\n",
      "78325\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "import seaborn as sns   # plotting heatmap\n",
    "\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing  #用來標準化刻度\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import logcosh, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "time=14\n",
    "to_time=time-1\n",
    "\n",
    "df_ca_train=pd.read_csv(\"mimic_ca_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_ca_test=pd.read_csv(\"mimic_ca_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "df_dead_train=pd.read_csv(\"mimic_dead_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_dead_test=pd.read_csv(\"mimic_dead_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "#######################殺資料###############################\n",
    "flag_ca_train=df_ca_train.shape[0] \n",
    "flag_ca_test=df_ca_test.shape[0]  \n",
    "\n",
    "flag_dead_train=df_dead_train.shape[0] \n",
    "flag_dead_test=df_dead_test.shape[0] \n",
    "\n",
    "for i in range(flag_ca_train): \n",
    "      if i%time== to_time: \n",
    "         df_ca_train=df_ca_train.drop([i])\n",
    "        \n",
    "for i in range(flag_ca_test): \n",
    "      if i%time== to_time: \n",
    "         df_ca_test=df_ca_test.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_train): \n",
    "      if i%time== to_time: \n",
    "         df_dead_train=df_dead_train.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_test): \n",
    "      if i%time== to_time: \n",
    "         df_dead_test=df_dead_test.drop([i])\n",
    "###########################################################\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "df_ca_train.to_csv('mimic_ca_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_ca_test.to_csv('mimic_ca_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_train.to_csv('mimic_dead_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_test.to_csv('mimic_dead_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280020, 12)\n",
      "(69992, 12)\n",
      "280020\n",
      "69992\n",
      "(313300, 12)\n",
      "(78325, 12)\n",
      "313300\n",
      "78325\n",
      "(258480, 12)\n",
      "(64608, 12)\n",
      "258480\n",
      "64608\n",
      "(289200, 12)\n",
      "(72300, 12)\n",
      "289200\n",
      "72300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "import seaborn as sns   # plotting heatmap\n",
    "\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing  #用來標準化刻度\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import logcosh, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "time=13\n",
    "to_time=time-1\n",
    "\n",
    "df_ca_train=pd.read_csv(\"mimic_ca_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_ca_test=pd.read_csv(\"mimic_ca_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "df_dead_train=pd.read_csv(\"mimic_dead_vital_sign_train_\"+str(time)+\"hours.csv\")\n",
    "df_dead_test=pd.read_csv(\"mimic_dead_vital_sign_test_\"+str(time)+\"hours.csv\")\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "#######################殺資料###############################\n",
    "flag_ca_train=df_ca_train.shape[0] \n",
    "flag_ca_test=df_ca_test.shape[0]  \n",
    "\n",
    "flag_dead_train=df_dead_train.shape[0] \n",
    "flag_dead_test=df_dead_test.shape[0] \n",
    "\n",
    "for i in range(flag_ca_train): \n",
    "      if i%time== to_time: \n",
    "         df_ca_train=df_ca_train.drop([i])\n",
    "        \n",
    "for i in range(flag_ca_test): \n",
    "      if i%time== to_time: \n",
    "         df_ca_test=df_ca_test.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_train): \n",
    "      if i%time== to_time: \n",
    "         df_dead_train=df_dead_train.drop([i])\n",
    "        \n",
    "for i in range(flag_dead_test): \n",
    "      if i%time== to_time: \n",
    "         df_dead_test=df_dead_test.drop([i])\n",
    "###########################################################\n",
    "\n",
    "print(df_ca_train.shape)\n",
    "print(df_ca_test.shape)\n",
    "print(df_ca_train.shape[0])\n",
    "print(df_ca_test.shape[0])\n",
    "\n",
    "print(df_dead_train.shape)\n",
    "print(df_dead_test.shape)\n",
    "print(df_dead_train.shape[0])\n",
    "print(df_dead_test.shape[0])\n",
    "\n",
    "df_ca_train.to_csv('mimic_ca_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_ca_test.to_csv('mimic_ca_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_train.to_csv('mimic_dead_vital_sign_train_'+str(to_time)+'hours.csv', index=False)\n",
    "df_dead_test.to_csv('mimic_dead_vital_sign_test_'+str(to_time)+'hours.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
