{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeline: (21540, 144)\n",
      "baseline: (21540, 70)\n",
      "timeline: (42320, 24, 6)\n",
      "baseline: (42320, 70)\n",
      "label: (42320,)\n",
      "timeline: (5384, 24, 6)\n",
      "baseline: (5384, 70)\n",
      "label: (5384, 1)\n",
      "timeline_no_smote: (21540, 24, 6)\n",
      "baseline_no_smote: (21540, 70)\n",
      "label_no_smote: (21540, 1)\n",
      "timeline_nr: (760, 24, 6)\n",
      "label_nr: (760,)\n"
     ]
    }
   ],
   "source": [
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(0)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(2)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(24)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(26)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "#from keras import backend as K\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "\n",
    "from sklearn import preprocessing  #用來標準化刻度\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import logcosh, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Import Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from time import time\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "####################################################################################  x_lstm_validation\n",
    "\n",
    "T=24\n",
    "\n",
    "train_cardiac_total=pd.read_csv(\"mimic_ca_vital_sign_train_\"+str(T)+\"hours.csv\")\n",
    "test_cardiac_total=pd.read_csv(\"mimic_ca_vital_sign_test_\"+str(T)+\"hours.csv\")\n",
    "train_cardiac_base_total=pd.read_csv(\"mimic_ca_baseline_total_v2.csv\")\n",
    "\n",
    "#eicu_cardiac_total=pd.read_csv(\"eicu_total_\"+str(T)+\"hours.csv\")\n",
    "eicu_cardiac_total=pd.read_csv(\"eicu_version2_\"+str(T)+\"hours.csv\")\n",
    "\n",
    "total_train=21540 #control+event\n",
    "total_test=5384 #control+event\n",
    "train_control=21160 #control\n",
    "\n",
    "total_eicu=10049 #control+event\n",
    "\n",
    "var=6\n",
    "random=32\n",
    "smote_ratio=1\n",
    "near_ratio=1\n",
    "EPOCH = 3                    # number of epochs\n",
    "BATCH = 32                      # batch size\n",
    "\n",
    "dropout=0.4\n",
    "LR = 0.001                           # learning rate of the gradient descent\n",
    "LAMBD = 0.001                       # lambda in L2 regularizaion\n",
    "\n",
    "#####################################################################################\n",
    "train_cardiac_base_total=train_cardiac_base_total.drop(['subject_id'],axis=1)\n",
    "train_cardiac_base_total=train_cardiac_base_total.drop(['hadm_id'],axis=1)\n",
    "train_cardiac_base_total=train_cardiac_base_total.drop(['stay_id'],axis=1)\n",
    "train_cardiac_base_total=train_cardiac_base_total.drop(['los'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['CA'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['hospDIED'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['cardR'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['DNR'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['CMO'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['DNRDNI'],axis=1)\n",
    "\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['DNI'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['FullCode'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['indextime'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['ccs9'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['ccs10'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['cardRv2'],axis=1)\n",
    "\n",
    "###############CXR##############\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Atelectasis'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Cardiomegaly'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Consolidation'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Edema'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Enlarged Cardiomediastinum'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Fracture'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Lung Lesion'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Lung Opacity'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['No Finding'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Pleural Effusion'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Pleural Other'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Pneumonia'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Pneumothorax'],axis=1)\n",
    "#train_cardiac_base_total=train_cardiac_base_total.drop(['Support Devices'],axis=1)\n",
    "###############CXR##############\n",
    "\n",
    "#train_cardiac_base_total=pd.get_dummies(data=train_cardiac_base_total,columns=[\"first_careunit\",\"ethnicity\",\"BMI\"])\n",
    "train_cardiac_base_total=pd.get_dummies(data=train_cardiac_base_total,columns=[\"first_careunit\",\"ethnicity\"])\n",
    "\n",
    "\n",
    "####################################################################\n",
    "df_train_base=train_cardiac_base_total[:total_train]\n",
    "y_train=df_train_base[['eventV3']].values   #取train_labels\n",
    "y_train_nr=df_train_base[['eventV3']].values   #取train_labels\n",
    "y_train_base=df_train_base[['eventV3']].values   #取train_labels\n",
    "y_train_no_smote=df_train_base[['eventV3']].values   #取train_labels\n",
    "df_train_base=df_train_base.drop(['eventV3'],axis=1)\n",
    "train_features=df_train_base.values\n",
    "\n",
    "df_test_base=train_cardiac_base_total[total_train:]\n",
    "y_test=df_test_base[['eventV3']].values   #取test_labels\n",
    "y_test_log=df_test_base['eventV3'].values   #取test_labels\n",
    "df_test_base=df_test_base.drop(['eventV3'],axis=1)\n",
    "test_features=df_test_base.values\n",
    "\n",
    "minmax_scale =preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "x_train_base=minmax_scale.fit_transform(train_features)\n",
    "x_test_base=minmax_scale.fit_transform(test_features)\n",
    "\n",
    "x_train_base_no_smote=minmax_scale.fit_transform(train_features)\n",
    "#x_train_base=train_features\n",
    "#x_test_base=test_features\n",
    "\n",
    "sm = SMOTE(random_state=random, sampling_strategy=smote_ratio)\n",
    "nr = NearMiss(sampling_strategy=near_ratio) \n",
    "\n",
    "x_train_base, y_train_base = sm.fit_sample(x_train_base, y_train_base.ravel())\n",
    "#x_train_base, y_train_base = nr.fit_sample(x_train_base, y_train_base.ravel())\n",
    "\n",
    "train_cardiac_total=train_cardiac_total[['vHR','vRR','vsbp','vdbp','vmbp','vspo2']]    \n",
    "train_cardiac_total=np.array(train_cardiac_total).reshape(total_train,T*var) #轉二維  array\n",
    "train_cardiac_total= pd.DataFrame(train_cardiac_total)\n",
    "\n",
    "x_test_lstm=test_cardiac_total[['vHR','vRR','vsbp','vdbp','vmbp','vspo2']].values \n",
    "#x_test_lstm=minmax_scale.fit_transform(x_test_lstm)  #規一化\n",
    "x_test_lstm=np.array(x_test_lstm).reshape(total_test,T,var) \n",
    "\n",
    "x_train_lstm, y_train = sm.fit_sample(train_cardiac_total, y_train.ravel())\n",
    "\n",
    "x_train_lstm_nr, y_train_nr = nr.fit_sample(train_cardiac_total, y_train_nr.ravel())\n",
    "\n",
    "#x_train_lstm=minmax_scale.fit_transform(x_train_lstm)  #規一化\n",
    "\n",
    "x_train_lstm=np.array(x_train_lstm).reshape(x_train_lstm.shape[0],T,var) #轉三維  total\n",
    "\n",
    "x_train_lstm_nr=np.array(x_train_lstm_nr).reshape(x_train_lstm_nr.shape[0],T,var) #轉三維  total\n",
    "\n",
    "x_train_lstm_no_smote=np.array(train_cardiac_total).reshape(train_cardiac_total.shape[0],T,var) #轉三維  total\n",
    "\n",
    "def roc_curve_and_score(y_test, pred_proba):\n",
    "    fpr, tpr, _ = roc_curve(y_test.ravel(), pred_proba.ravel())\n",
    "    roc_auc = roc_auc_score(y_test.ravel(), pred_proba.ravel())\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "print('timeline:',train_cardiac_total.shape)\n",
    "print('baseline:',df_train_base.shape)\n",
    "\n",
    "print('timeline:',x_train_lstm.shape)\n",
    "print('baseline:',x_train_base.shape)\n",
    "print('label:',y_train.shape)\n",
    "\n",
    "print('timeline:',x_test_lstm.shape)\n",
    "print('baseline:',x_test_base.shape)\n",
    "print('label:',y_test.shape)\n",
    "\n",
    "print('timeline_no_smote:',x_train_lstm_no_smote.shape)\n",
    "print('baseline_no_smote:',x_train_base_no_smote.shape)\n",
    "print('label_no_smote:',y_train_no_smote.shape)\n",
    "\n",
    "\n",
    "print('timeline_nr:',x_train_lstm_nr.shape)\n",
    "print('label_nr:',y_train_nr.shape)\n",
    "#print(df_train_base.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42320, 24, 6)\n",
      "(42320,)\n",
      "layers=[8, 8, 8, 1], train_examples=42320, test_examples=5384\n",
      "batch = 32, timesteps = 24, features = 6, epochs = 3\n",
      "lr = 0.001, lambda = 0.001, dropout = 1, recurr_dropout = 1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 24, 8)             480       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 24, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,673\n",
      "Trainable params: 1,625\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 33856 samples, validate on 8464 samples\n",
      "Epoch 1/3\n",
      " - 32s - loss: 0.5993 - accuracy: 0.7330 - f1_m: 0.5635 - precision_m: 0.7490 - val_loss: 0.8347 - val_accuracy: 0.4955 - val_f1_m: 0.6574 - val_precision_m: 1.0000\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,val_f1_m,val_precision_m,loss,accuracy,f1_m,precision_m,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 30s - loss: 0.5453 - accuracy: 0.7657 - f1_m: 0.5987 - precision_m: 0.8290 - val_loss: 0.6995 - val_accuracy: 0.5633 - val_f1_m: 0.7159 - val_precision_m: 1.0000\n",
      "Epoch 3/3\n",
      " - 29s - loss: 0.5292 - accuracy: 0.7723 - f1_m: 0.6115 - precision_m: 0.8387 - val_loss: 0.7610 - val_accuracy: 0.5183 - val_f1_m: 0.6770 - val_precision_m: 1.0000\n",
      "-----------------------------------------------------------------\n",
      "Training was completed in 93.82 secs\n",
      "-----------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "train accuracy = 73.6673%\n",
      "test accuracy = 95.078%\n",
      "test error = 265 out of 5384 examples\n"
     ]
    }
   ],
   "source": [
    "print(x_train_lstm.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm.shape[0]           # number of training examples (2D)\n",
    "#M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_smote = Sequential()\n",
    "\n",
    "model_smote.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_smote.add(Dropout(dropout))\n",
    "model_smote.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_smote.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_smote.add(Dropout(dropout))\n",
    "model_smote.add(BatchNormalization())\n",
    "\n",
    "model_smote.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_smote.add(Dropout(dropout))\n",
    "model_smote.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_smote.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_smote.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_smote.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_smote.fit(x_train_lstm, y_train,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0.2,\n",
    "                    #validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_smote.evaluate(x_train_lstm, y_train,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_smote.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_smote= model_smote.predict(x_test_lstm)\n",
    "\n",
    "predict_test_smote=[]\n",
    "for i in range(y_pred_smote.shape[0]): \n",
    "    if y_pred_smote[i]>0.5:\n",
    "        predict_test_smote.append(1)\n",
    "    else:\n",
    "        predict_test_smote.append(0)\n",
    "predict_test_smote = np.array(predict_test_smote)\n",
    "print(predict_test_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[5068  221]\n",
      " [  44   51]]\n",
      "smote_accuracy:0.95\n",
      "smote_auc:  0.79\n",
      "smote_sensitivity : 0.54\n",
      "smote_specificity : 0.96\n",
      "ppv: 0.1875\n",
      "npv: 0.9913928012519562\n"
     ]
    }
   ],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_smote,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_smote)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "smote_accuracy= (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,1]+cm1[1,0])   #FPR\n",
    "\n",
    "fpr, tpr, smote_roc_auc = roc_curve_and_score(y_test, y_pred_smote)\n",
    "\n",
    "smote_specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "smote_sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('smote_accuracy:%0.2f' %smote_accuracy)\n",
    "print('smote_auc:  %0.2f' %smote_roc_auc)\n",
    "print('smote_sensitivity : %0.2f' %smote_sensitivity)\n",
    "print('smote_specificity : %0.2f' %smote_specificity)\n",
    "\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_test, y_pred_smote) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('smote')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20566174],\n",
       "       [0.20571816],\n",
       "       [0.19055822],\n",
       "       ...,\n",
       "       [0.93797714],\n",
       "       [0.20591973],\n",
       "       [0.20507401]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(760, 24, 6)\n",
      "(760,)\n",
      "layers=[8, 8, 8, 1], train_examples=760, test_examples=5384\n",
      "batch = 32, timesteps = 24, features = 6, epochs = 3\n",
      "lr = 0.001, lambda = 0.001, dropout = 1, recurr_dropout = 1\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 24, 8)             480       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 24, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,673\n",
      "Trainable params: 1,625\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 608 samples, validate on 152 samples\n",
      "Epoch 1/3\n",
      " - 2s - loss: 0.8047 - accuracy: 0.4934 - f1_m: 0.3761 - precision_m: 0.3378 - val_loss: 0.7813 - val_accuracy: 0.0000e+00 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,val_f1_m,val_precision_m,loss,accuracy,f1_m,precision_m,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.7752 - accuracy: 0.5345 - f1_m: 0.4266 - precision_m: 0.3999 - val_loss: 0.8113 - val_accuracy: 0.0000e+00 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00\n",
      "Epoch 3/3\n",
      " - 1s - loss: 0.7669 - accuracy: 0.5378 - f1_m: 0.3571 - precision_m: 0.3714 - val_loss: 0.8307 - val_accuracy: 0.0000e+00 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00\n",
      "-----------------------------------------------------------------\n",
      "Training was completed in 6.14 secs\n",
      "-----------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "train accuracy = 50.0%\n",
      "test accuracy = 98.2355%\n",
      "test error = 95 out of 5384 examples\n"
     ]
    }
   ],
   "source": [
    "print(x_train_lstm_nr.shape)\n",
    "print(y_train_nr.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_nr.shape[0]           # number of training examples (2D)\n",
    "#M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_nr = Sequential()\n",
    "\n",
    "model_nr.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_nr.add(Dropout(dropout))\n",
    "model_nr.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_nr.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_nr.add(Dropout(dropout))\n",
    "model_nr.add(BatchNormalization())\n",
    "\n",
    "model_nr.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_nr.add(Dropout(dropout))\n",
    "model_nr.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_nr.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_nr.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_nr.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_nr.fit(x_train_lstm_nr, y_train_nr,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0.2,\n",
    "                    #validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_nr.evaluate(x_train_lstm_nr, y_train_nr,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_nr.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_nr= model_nr.predict(x_test_lstm)\n",
    "\n",
    "predict_test_nr=[]\n",
    "for i in range(y_pred_nr.shape[0]): \n",
    "    if y_pred_nr[i]>0.5:\n",
    "        predict_test_nr.append(1)\n",
    "    else:\n",
    "        predict_test_nr.append(0)\n",
    "predict_test_nr = np.array(predict_test_nr)\n",
    "print(predict_test_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[5289    0]\n",
      " [  95    0]]\n",
      "nr_accuracy: 0.98\n",
      "nr_auc: 0.51\n",
      "nr_sensitivity: 0.00\n",
      "nr_specificity: 1.00\n",
      "ppv: nan\n",
      "npv: 0.9823551263001485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    }
   ],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_nr,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_nr)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "nr_accuracy= (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,1]+cm1[1,0])   #FPR\n",
    "\n",
    "fpr, tpr, nr_roc_auc = roc_curve_and_score(y_test, y_pred_nr)\n",
    "nr_specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "nr_sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('nr_accuracy: %0.2f' %nr_accuracy)\n",
    "print('nr_auc: %0.2f' %nr_roc_auc)\n",
    "print('nr_sensitivity: %0.2f' %nr_sensitivity)\n",
    "print('nr_specificity: %0.2f' %nr_specificity)\n",
    "\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_test, y_pred_nr) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('nr')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33856, 24, 6)\n",
      "(8464, 24, 6)\n",
      "(33856,)\n",
      "(8464,)\n",
      "layers=[8, 8, 8, 1], train_examples=33856, test_examples=5384\n",
      "batch = 32, timesteps = 24, features = 6, epochs = 3\n",
      "lr = 0.001, lambda = 0.001, dropout = 1, recurr_dropout = 1\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 24, 8)             480       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 24, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,673\n",
      "Trainable params: 1,625\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 33856 samples, validate on 8464 samples\n",
      "Epoch 1/3\n",
      " - 32s - loss: 0.6738 - accuracy: 0.6440 - f1_m: 0.6026 - precision_m: 0.7014 - val_loss: 0.5670 - val_accuracy: 0.7371 - val_f1_m: 0.3760 - val_precision_m: 0.5019\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,val_f1_m,val_precision_m,loss,accuracy,f1_m,precision_m,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 30s - loss: 0.5859 - accuracy: 0.7096 - f1_m: 0.6377 - precision_m: 0.8414 - val_loss: 0.5394 - val_accuracy: 0.7466 - val_f1_m: 0.3608 - val_precision_m: 0.5019\n",
      "Epoch 3/3\n",
      " - 30s - loss: 0.5730 - accuracy: 0.7156 - f1_m: 0.6393 - precision_m: 0.8571 - val_loss: 0.5275 - val_accuracy: 0.7473 - val_f1_m: 0.3748 - val_precision_m: 0.5019\n",
      "-----------------------------------------------------------------\n",
      "Training was completed in 95.14 secs\n",
      "-----------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "train accuracy = 74.4152%\n",
      "test accuracy = 88.373%\n",
      "test error = 626 out of 5384 examples\n"
     ]
    }
   ],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo1\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[part_0:], x_event_1[part_1:]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[:part_0], x_event_1[:part_1]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[part_0:], y_event_1[part_1:]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[:part_0], y_event_1[:part_1]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_1.add(Dropout(dropout))\n",
    "model_1.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_1.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_1.add(Dropout(dropout))\n",
    "model_1.add(BatchNormalization())\n",
    "\n",
    "model_1.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_1.add(Dropout(dropout))\n",
    "model_1.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_1.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_1.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_1.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_1.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_1.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_1.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred1= model_1.predict(x_test_lstm)\n",
    "predict_train_lstm1=model_1.predict(x_train_lstm)\n",
    "\n",
    "test_acc_1=test_acc\n",
    "test_precision_1=test_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "predict_test_1=[]\n",
    "for i in range(y_pred1.shape[0]): \n",
    "    if y_pred1[i]>0.5:\n",
    "        predict_test_1.append(1)\n",
    "    else:\n",
    "        predict_test_1.append(0)\n",
    "predict_test_1 = np.array(predict_test_1)\n",
    "print(predict_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[4708  581]\n",
      " [  45   50]]\n",
      "sensitivity: 0.5263157894736842\n",
      "specificity: 0.8901493666099451\n",
      "ppv: 0.07923930269413629\n",
      "npv: 0.9905322953923837\n"
     ]
    }
   ],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_1,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_1)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('sensitivity:',sensitivity)\n",
    "print('specificity:',specificity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33856, 24, 6)\n",
      "(8464, 24, 6)\n",
      "(33856,)\n",
      "(8464,)\n",
      "layers=[8, 8, 8, 1], train_examples=33856, test_examples=5384\n",
      "batch = 32, timesteps = 24, features = 6, epochs = 3\n",
      "lr = 0.001, lambda = 0.001, dropout = 1, recurr_dropout = 1\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 24, 8)             480       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 24, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,673\n",
      "Trainable params: 1,625\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 33856 samples, validate on 8464 samples\n",
      "Epoch 1/3\n",
      " - 33s - loss: 0.6555 - accuracy: 0.6575 - f1_m: 0.6239 - precision_m: 0.6956 - val_loss: 0.5266 - val_accuracy: 0.7531 - val_f1_m: 0.4449 - val_precision_m: 0.5015\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,val_f1_m,val_precision_m,loss,accuracy,f1_m,precision_m,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 31s - loss: 0.5525 - accuracy: 0.7346 - f1_m: 0.7084 - precision_m: 0.7863 - val_loss: 0.5056 - val_accuracy: 0.7526 - val_f1_m: 0.4395 - val_precision_m: 0.5015\n",
      "Epoch 3/3\n",
      " - 32s - loss: 0.5402 - accuracy: 0.7429 - f1_m: 0.7122 - precision_m: 0.8083 - val_loss: 0.4965 - val_accuracy: 0.7687 - val_f1_m: 0.3871 - val_precision_m: 0.5014\n",
      "-----------------------------------------------------------------\n",
      "Training was completed in 98.65 secs\n",
      "-----------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "train accuracy = 77.36%\n",
      "test accuracy = 89.6545%\n",
      "test error = 557 out of 5384 examples\n"
     ]
    }
   ],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo2\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[:part_0], x_event_1[:part_1],x_event_0[2*part_0:],x_event_1[2*part_1:]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[part_0:2*part_0], x_event_1[part_1:2*part_1]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[:part_0], y_event_1[:part_1],y_event_0[2*part_0:], y_event_1[2*part_1:]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[part_0:2*part_0], y_event_1[part_1:2*part_1]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "             #  dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_2.add(Dropout(dropout))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_2.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "             #  dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_2.add(Dropout(dropout))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_2.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_2.add(Dropout(dropout))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_2.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_2.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_2.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_2.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_2.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_2.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred2= model_2.predict(x_test_lstm)\n",
    "predict_train_lstm2=model_2.predict(x_train_lstm)\n",
    "\n",
    "test_acc_2=test_acc\n",
    "test_precision_2=test_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "predict_test_2=[]\n",
    "for i in range(y_pred2.shape[0]): \n",
    "    if y_pred2[i]>0.5:\n",
    "        predict_test_2.append(1)\n",
    "    else:\n",
    "        predict_test_2.append(0)\n",
    "predict_test_2 = np.array(predict_test_2)\n",
    "print(predict_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[4766  523]\n",
      " [  34   61]]\n",
      "specificity: 0.9011155227831348\n",
      "sensitivity: 0.6421052631578947\n",
      "ppv: 0.10445205479452055\n",
      "npv: 0.9929166666666667\n"
     ]
    }
   ],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_2,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_2)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])   \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33856, 24, 6)\n",
      "(8464, 24, 6)\n",
      "(33856,)\n",
      "(8464,)\n",
      "layers=[8, 8, 8, 1], train_examples=33856, test_examples=5384\n",
      "batch = 32, timesteps = 24, features = 6, epochs = 3\n",
      "lr = 0.001, lambda = 0.001, dropout = 1, recurr_dropout = 1\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 24, 8)             480       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 24, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,673\n",
      "Trainable params: 1,625\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 33856 samples, validate on 8464 samples\n",
      "Epoch 1/3\n",
      " - 32s - loss: 0.6786 - accuracy: 0.6498 - f1_m: 0.6112 - precision_m: 0.6989 - val_loss: 0.5930 - val_accuracy: 0.6895 - val_f1_m: 0.2992 - val_precision_m: 0.5016\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,val_f1_m,val_precision_m,loss,accuracy,f1_m,precision_m,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 31s - loss: 0.5958 - accuracy: 0.7040 - f1_m: 0.6513 - precision_m: 0.7872 - val_loss: 0.5614 - val_accuracy: 0.7199 - val_f1_m: 0.3449 - val_precision_m: 0.5016\n",
      "Epoch 3/3\n",
      " - 32s - loss: 0.5680 - accuracy: 0.7242 - f1_m: 0.6798 - precision_m: 0.8080 - val_loss: 0.5431 - val_accuracy: 0.7242 - val_f1_m: 0.3292 - val_precision_m: 0.5016\n",
      "-----------------------------------------------------------------\n",
      "Training was completed in 98.53 secs\n",
      "-----------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "train accuracy = 72.9826%\n",
      "test accuracy = 95.2637%\n",
      "test error = 255 out of 5384 examples\n"
     ]
    }
   ],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo3\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[:2*part_0], x_event_1[:2*part_1],x_event_0[3*part_0:],x_event_1[3*part_1:]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[2*part_0:3*part_0], x_event_1[2*part_1:3*part_1]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[:2*part_0], y_event_1[:2*part_1],y_event_0[3*part_0:], y_event_1[3*part_1:]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[2*part_0:3*part_0], y_event_1[2*part_1:3*part_1]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_3.add(Dropout(dropout))\n",
    "model_3.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_3.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "             #  dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_3.add(Dropout(dropout))\n",
    "model_3.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_3.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "             #  dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_3.add(Dropout(dropout))\n",
    "model_3.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_3.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_3.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_3.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_3.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_3.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_3.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred3= model_3.predict(x_test_lstm)\n",
    "predict_train_lstm3=model_3.predict(x_train_lstm)\n",
    "\n",
    "test_acc_3=test_acc\n",
    "test_precision_3=test_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "predict_test_3=[]\n",
    "for i in range(y_pred3.shape[0]): \n",
    "    if y_pred3[i]>0.5:\n",
    "        predict_test_3.append(1)\n",
    "    else:\n",
    "        predict_test_3.append(0)\n",
    "predict_test_3 = np.array(predict_test_3)\n",
    "print(predict_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[5081  208]\n",
      " [  47   48]]\n",
      "specificity: 0.9606730951030441\n",
      "sensitivity: 0.5052631578947369\n",
      "ppv: 0.1875\n",
      "npv: 0.9908346333853354\n"
     ]
    }
   ],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_3,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_3)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33856, 24, 6)\n",
      "(8464, 24, 6)\n",
      "(33856,)\n",
      "(8464,)\n",
      "layers=[8, 8, 8, 1], train_examples=33856, test_examples=5384\n",
      "batch = 32, timesteps = 24, features = 6, epochs = 3\n",
      "lr = 0.001, lambda = 0.001, dropout = 1, recurr_dropout = 1\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 24, 8)             480       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 24, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 24, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 24, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,673\n",
      "Trainable params: 1,625\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 33856 samples, validate on 8464 samples\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo4\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[:3*part_0], x_event_1[:3*part_1],x_event_0[4*part_0:],x_event_1[4*part_1:]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[3*part_0:4*part_0], x_event_1[3*part_1:4*part_1]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[:3*part_0], y_event_1[:3*part_1],y_event_0[4*part_0:], y_event_1[4*part_1:]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[3*part_0:4*part_0], y_event_1[3*part_1:4*part_1]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_4 = Sequential()\n",
    "\n",
    "model_4.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "              # dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_4.add(Dropout(dropout))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_4.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "            #   dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_4.add(Dropout(dropout))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_4.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "           #    dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_4.add(Dropout(dropout))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_4.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_4.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_4.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_4.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_4.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_4.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred4= model_4.predict(x_test_lstm)\n",
    "predict_train_lstm4=model_4.predict(x_train_lstm)\n",
    "\n",
    "test_acc_4=test_acc\n",
    "test_precision_4=test_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_4=[]\n",
    "for i in range(y_pred4.shape[0]): \n",
    "    if y_pred4[i]>0.5:\n",
    "        predict_test_4.append(1)\n",
    "    else:\n",
    "        predict_test_4.append(0)\n",
    "predict_test_4 = np.array(predict_test_4)\n",
    "print(predict_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_4,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_4)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])   \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_event_0=x_train_lstm[:train_control]   #切出正常組 事件組   #loo5\n",
    "y_event_0=y_train[:train_control]\n",
    "\n",
    "x_event_1=x_train_lstm[train_control:]\n",
    "y_event_1=y_train[train_control:]\n",
    "\n",
    "part_0=int(int(x_event_0.shape[0])/5)\n",
    "part_1=int(int(x_event_1.shape[0])/5)\n",
    "\n",
    "x_train_lstm_new=np.concatenate((x_event_0[:4*part_0], x_event_1[:4*part_1]))\n",
    "x_valid_lstm_new=np.concatenate((x_event_0[4*part_0:], x_event_1[4*part_1:]))\n",
    "\n",
    "y_train_lstm_new=np.concatenate((y_event_0[:4*part_0], y_event_1[:4*part_1]))\n",
    "y_valid_lstm_new=np.concatenate((y_event_0[4*part_0:], y_event_1[4*part_1:]))\n",
    "\n",
    "print(x_train_lstm_new.shape)\n",
    "print(x_valid_lstm_new.shape)\n",
    "\n",
    "print(y_train_lstm_new.shape)\n",
    "print(y_valid_lstm_new.shape)\n",
    "\n",
    "LAYERS = [8,8,8,1]                # number of units in hidden and output layers\n",
    "M_TRAIN = x_train_lstm_new.shape[0]           # number of training examples (2D)\n",
    "M_VALIDATION =x_valid_lstm_new.shape[0]  \n",
    "M_TEST = x_test_lstm.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = x_train_lstm.shape[2]                 # number of features\n",
    "\n",
    "#BATCH = M_TRAIN                          # batch size\n",
    "DP = 1                            # dropout rate\n",
    "RDP = 1                          # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
    "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# Build the Model\n",
    "model_5 = Sequential()\n",
    "\n",
    "model_5.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "            #   dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_5.add(Dropout(dropout))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_5.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "            #   dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_5.add(Dropout(dropout))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_5.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "           #    dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model_5.add(Dropout(dropout))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_5.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model_5.compile(loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m], optimizer=Adam(lr=LR))\n",
    "\n",
    "print(model_5.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "start = time()\n",
    "\n",
    "##################################################\n",
    "\n",
    "History = model_5.fit(x_train_lstm_new, y_train_lstm_new,\n",
    "                    epochs=EPOCH,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0,\n",
    "                    validation_data=(x_valid_lstm_new[:M_VALIDATION], y_valid_lstm_new[:M_VALIDATION]),\n",
    "                    #validation_data=(x_test_lstm[:M_TEST], y_test[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_decay, early_stop])\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time() - start:.2f} secs')\n",
    "print('-'*65)\n",
    "# Evaluate the model:\n",
    "train_loss, train_acc, train_f1_score, train_precision = model_5.evaluate(x_train_lstm_new, y_train_lstm_new,\n",
    "                                       batch_size=BATCH, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_f1_score, test_precision = model_5.evaluate(x_test_lstm[:M_TEST], y_test[:M_TEST],\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
    "\n",
    "y_pred5= model_5.predict(x_test_lstm)\n",
    "predict_train_lstm5=model_5.predict(x_train_lstm)\n",
    "\n",
    "test_acc_5=test_acc\n",
    "test_precision_5=test_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_5=[]\n",
    "for i in range(y_pred5.shape[0]): \n",
    "    if y_pred5[i]>0.5:\n",
    "        predict_test_5.append(1)\n",
    "    else:\n",
    "        predict_test_5.append(0)\n",
    "predict_test_5 = np.array(predict_test_5)\n",
    "print(predict_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_5,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_5)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_temp=np.append(y_pred1,y_pred2)\n",
    "y_pred_temp=np.append(y_pred_temp,y_pred3)\n",
    "y_pred_temp=np.append(y_pred_temp,y_pred4)\n",
    "y_pred_temp=np.append(y_pred_temp,y_pred5)\n",
    "\n",
    "predict_train_temp=np.append(predict_train_lstm1,predict_train_lstm2)\n",
    "predict_train_temp=np.append(predict_train_temp,predict_train_lstm3)\n",
    "predict_train_temp=np.append(predict_train_temp,predict_train_lstm4)\n",
    "predict_train_temp=np.append(predict_train_temp,predict_train_lstm5)\n",
    "\n",
    "y_pred=np.array(y_pred_temp).reshape(x_test_lstm.shape[0],5, order='F') #轉維\n",
    "predict_train_lstm=np.array(predict_train_temp).reshape(x_train_lstm.shape[0],5, order='F') #轉維\n",
    "\n",
    "y_pred= np.mean(y_pred, axis=1)\n",
    "predict_train_lstm= np.mean(predict_train_lstm, axis=1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test=[]\n",
    "for i in range(y_pred.shape[0]): \n",
    "    if y_pred[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "print(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "#predict_train_lstm = model.predict(x_train_lstm)\n",
    "#predict_train_lstm=np.array(predict_train_lstm).reshape(total_train.shape[0]) #37536\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "accuracy_5_fold=(cm1[0,0]+cm1[1,1])/(cm1[1,1]+cm1[0,0]+cm1[0,1]+cm1[1,0])\n",
    "\n",
    "fpr, tpr, fold_roc_auc = roc_curve_and_score(y_test, y_pred)\n",
    "\n",
    "specificity_5_fold = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity_5_fold = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[0,1])  \n",
    "\n",
    "print('5_fold_accuracy : %0.2f' %accuracy_5_fold)  #accuracy\n",
    "print('5_fold_auc : %0.2f' %fold_roc_auc)  #accuracy\n",
    "print('5_fold_sensitivity: %0.2f' %sensitivity_5_fold)\n",
    "print('5_fold_specificity: %0.2f' %specificity_5_fold)\n",
    "\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n",
    "\n",
    "\n",
    "y_pred=np.array(y_pred).reshape(total_test)\n",
    "\n",
    "flag=0\n",
    "total_predict=0\n",
    "for i in range(y_pred.shape[0]): \n",
    "      if y_pred[i]>0.5:\n",
    "            total_predict=total_predict+y_pred[i]\n",
    "            flag=flag+1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_test, y_pred) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('5 fold LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy : %0.2f' %accuracy_5_fold)  #accuracy\n",
    "print('AUC : %0.2f' % roc_auc)  #AUC\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n",
    "#print('f1_score :%0.2f' %test_f1_score)  #f1_score\n",
    "print(total_predict/flag*100)  #score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics,ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import model_selection\n",
    "\n",
    "forest = ensemble.RandomForestClassifier()\n",
    "\n",
    "rf_params = {\n",
    "'n_estimators': [15,20,25],\n",
    "'max_depth': [4,5,6,7]\n",
    " }\n",
    "\n",
    "forest = model_selection.GridSearchCV(forest, rf_params, cv=5)\n",
    "forest = forest.fit(x_train_base, y_train)\n",
    "\n",
    "prob_predict_y_validation1 = forest.predict_proba(x_train_base)#给出带有概率值的结果，每个点所有label的概率和为1\n",
    "prob_predict_y_validation = forest.predict_proba(x_test_base)#给出带有概率值的结果，每个点所有label的概率和为1\n",
    "\n",
    "\n",
    "y_score = prob_predict_y_validation[:, 1]\n",
    "# 預測\n",
    "predict_train_rf = prob_predict_y_validation1[:, 1]\n",
    "\n",
    "test_y_predicted = forest.predict(x_test_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc  ###計算roc和auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def roc_curve_and_score(y_test, pred_proba):\n",
    "    fpr, tpr, _ = roc_curve(y_test.ravel(), pred_proba.ravel())\n",
    "    roc_auc = roc_auc_score(y_test.ravel(), pred_proba.ravel())\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "#plt.grid()\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_score)\n",
    "plt.plot(fpr, tpr, color='#00db00', lw=2,\n",
    "         label='Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "plt.title('Random Forest')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test=[]\n",
    "for i in range(y_score.shape[0]): \n",
    "    if y_score[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "Accuracy  = (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,0]+cm1[1,1])   \n",
    "\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "\n",
    "print('Accuracy : %0.2f' %Accuracy)  #Accuracy\n",
    "print('AUC : %0.2f' % roc_auc)  #AUC\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train_base, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train_logistic_result = logreg.predict_proba(x_train_base)\n",
    "\n",
    "predict_train_logistic = predict_train_logistic_result[:, 1]\n",
    "\n",
    "logreg_test_y_predicted = logreg.predict_proba(x_test_base)\n",
    "\n",
    "log_y_score = logreg_test_y_predicted[:, 1]\n",
    "\n",
    "predict_test=[]\n",
    "for i in range(log_y_score.shape[0]): \n",
    "    if log_y_score[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "#print(predict_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score,recall_score,confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test,predict_test)\n",
    "\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "\n",
    "#print('Precision:',precision_score(y_test_1, predict_test))\n",
    "#print('Recall:', recall_score(y_test_1, predict_test))\n",
    "#print('f1-score: %f' % f1_score(y_test_1, predict_test))\n",
    "print('Accuracy: %f' % accuracy_score(y_test, predict_test))\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n",
    "\n",
    "pd.crosstab(y_test_log,predict_test,rownames=['label'],colnames=['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc  ###計算roc和auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "#plt.grid()\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, log_y_score)\n",
    "plt.plot(fpr, tpr, color='#00db00', lw=2,\n",
    "         label='Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "plt.title('logistic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_train_logistic)\n",
    "print(predict_train_lstm)\n",
    "\n",
    "stacking=np.append(predict_train_logistic, predict_train_lstm)\n",
    "x_train_stacking=np.array(stacking).reshape(x_train_lstm.shape[0],2, order='F') #轉維\n",
    "\n",
    "from sklearn import  svm, preprocessing, metrics \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "svm_stacking = svm.SVC(kernel='linear',probability=True)\n",
    "svm_stacking.fit(x_train_stacking,y_train)\n",
    "\n",
    "print(x_train_stacking.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(log_y_score.shape)#logistic test 機率\n",
    "print(y_pred.shape)#lstm test 機率 \n",
    "print(y_score.shape)#Rf test 機率\n",
    "\n",
    "stacking_test=np.append(y_pred, log_y_score)\n",
    "x_test_stacking=np.array(stacking_test).reshape(total_test,2, order='F') #轉維\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=svm_stacking.predict(x_test_stacking)\n",
    "predict_pro_stacking=svm_stacking.predict_proba(x_test_stacking)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, predict)\n",
    "precision  = metrics.precision_score(y_test, predict)\n",
    "\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict,rownames=['label'],colnames=['predict'])\n",
    "predict_pro_stacking=predict_pro_stacking[:,1:2]\n",
    "\n",
    "#################92個test ca 輸出#####################\n",
    "#test=pd.DataFrame(predict[4689:])\n",
    "#test.to_csv('24hour_ca.csv', index=False)\n",
    "####################################### predict_pro_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_stacking=[]\n",
    "for i in range(predict_pro_stacking.shape[0]): \n",
    "    if predict_pro_stacking[i]>0.5:\n",
    "        predict_test_stacking.append(1)\n",
    "    else:\n",
    "        predict_test_stacking.append(0)\n",
    "predict_test_stacking = np.array(predict_test_stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(y_test_1D,predict_test,rownames=['label'],colnames=['predict'])  \n",
    "\n",
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_stacking)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "fpr, tpr, stacking_svm_roc_auc = roc_curve_and_score(y_test, predict_pro_stacking)\n",
    "\n",
    "stacking_svm_accuracy=(cm1[0,0]+cm1[1,1])/(cm1[1,1]+cm1[0,0]+cm1[0,1]+cm1[1,0])\n",
    "\n",
    "stacking_svm_specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "stacking_svm_sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[0,1]) \n",
    "\n",
    "\n",
    "print('stacking_svm_Accuracy: %0.2f' %stacking_svm_accuracy)\n",
    "print('stacking_svm_auc: %0.2f' %stacking_svm_roc_auc)\n",
    "print('stacking_svm_sensitivity: %0.2f' %stacking_svm_sensitivity)\n",
    "print('stacking_svm_specificity: %0.2f' %stacking_svm_specificity)\n",
    "\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n",
    "flag=0\n",
    "total_predict=0\n",
    "for i in range(y_pred.shape[0]): \n",
    "      if predict_pro_stacking[i]>0.5:\n",
    "            total_predict=total_predict+predict_pro_stacking[i]\n",
    "            flag=flag+1\n",
    "#print(flag)  #score\n",
    "\n",
    "#print(y_test_1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_test, predict_pro_stacking) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('stacking LSTM(SVM)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy : %0.2f' %accuracy)  #Accuracy\n",
    "print('precision : %0.2f' %precision)  #precision\n",
    "print('AUC : %0.2f' % roc_auc)  #AUC\n",
    "print('Sensitivity : %0.2f' % sensitivity )\n",
    "print('Specificity :%0.2f' % specificity)\n",
    "#print('f1_score :%0.2f' %test_f1_score)  #f1_score\n",
    "print(total_predict/flag*100)  #score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc  ###計算roc和auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics,ensemble\n",
    "from sklearn import model_selection\n",
    "\n",
    "gbm = xgb.XGBRegressor()\n",
    "\n",
    "xgb_params = {\n",
    "'learning_rate': [0.1,0.2,0.5],\n",
    "'n_estimators': [30,50,100],\n",
    "'max_depth': [5,10,20],\n",
    " 'alpha': [0.4,0.6],\n",
    " }\n",
    "\n",
    "xg_reg = model_selection.GridSearchCV(gbm, xgb_params, cv=5)\n",
    "xg_reg.fit(x_train_stacking,y_train)\n",
    "\n",
    "y_pred_xgb = xg_reg.predict(x_test_stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_xgb=[]\n",
    "for i in range(y_pred_xgb.shape[0]): \n",
    "    if y_pred_xgb[i]>0.5:\n",
    "        predict_test_xgb.append(1)\n",
    "    else:\n",
    "        predict_test_xgb.append(0)\n",
    "predict_test_xgb = np.array(predict_test_xgb)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_xgb,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_xgb)\n",
    "\n",
    "fpr, tpr, stacking_xg_roc_auc = roc_curve_and_score(y_test, y_pred_xgb)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "stacking_xg_accuracy=(cm1[0,0]+cm1[1,1])/(cm1[1,1]+cm1[0,0]+cm1[0,1]+cm1[1,0])\n",
    "\n",
    "stacking_xg_specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "stacking_xg_sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "\n",
    "\n",
    "print('stacking_xg_accuracy : %0.2f' % stacking_xg_accuracy )\n",
    "print('stacking_xg_auc : %0.2f' % stacking_xg_roc_auc )\n",
    "print('stacking_xg_Sensitivity : %0.2f' % stacking_xg_sensitivity )\n",
    "print('stacking_xg_Specificity :%0.2f' % stacking_xg_specificity)\n",
    "\n",
    "accuracy=(cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,0]+cm1[1,1])\n",
    "print('accuracy :%0.2f' % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics,ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "forest_stacking = ensemble.RandomForestClassifier()\n",
    "\n",
    "rf_params = {\n",
    "'n_estimators': [15,20,25],\n",
    "'max_depth': [4,5,6,7]\n",
    "#'n_estimators': [5],\n",
    "#'max_depth': [5]\n",
    " }\n",
    "\n",
    "forest_stacking = model_selection.GridSearchCV(forest_stacking, rf_params, cv=5)\n",
    "forest_fit=forest_stacking.fit(x_train_stacking,y_train)\n",
    "\n",
    "prob_predict_y_validation_stacking = forest_stacking.predict_proba(x_test_stacking)#给出带有概率值的结果，每个点所有label的概率和为1\n",
    "y_score_stacking = prob_predict_y_validation_stacking[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test=[]\n",
    "for i in range(y_score_stacking.shape[0]): \n",
    "    if y_score_stacking[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "stacking_rf_specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "stacking_rf_sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "\n",
    "fpr,tpr,stacking_rf_roc_auc = roc_curve_and_score(y_test, y_score_stacking) ###計算真正率和假正率\n",
    "\n",
    "stacking_rf_accuracy=(cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,0]+cm1[1,1])\n",
    "\n",
    "print('stacking_rf_accuracy :%0.2f' % stacking_rf_accuracy)\n",
    "print('stacking_rf_roc_auc : %0.2f' % stacking_rf_roc_auc)  #AUC\n",
    "print('stacking_rf_sensitivity : %0.2f' % stacking_rf_sensitivity )\n",
    "print('stacking_rf_Specificity :%0.2f' % stacking_rf_specificity)\n",
    "\n",
    "print(forest_stacking.best_params_)\n",
    "print(forest_stacking.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh.fit(x_train_stacking, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nei_test_y_predicted = neigh.predict(x_test_stacking)\n",
    "predict_test=[]\n",
    "for i in range(nei_test_y_predicted.shape[0]): \n",
    "    if nei_test_y_predicted[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "#print(predict_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score,recall_score,confusion_matrix\n",
    "fpr, tpr, stacking_nei_roc_auc = roc_curve_and_score(y_test, nei_test_y_predicted)\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test)\n",
    "\n",
    "stacking_nei_accuracy=(cm1[0,0]+cm1[1,1])/(cm1[1,1]+cm1[0,0]+cm1[0,1]+cm1[1,0])\n",
    "stacking_nei_sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "stacking_nei_specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "\n",
    "#print('Precision:',precision_score(y_test_1, predict_test))\n",
    "#print('Recall:', recall_score(y_test_1, predict_test))\n",
    "#print('f1-score: %f' % f1_score(y_test_1, predict_test))\n",
    "\n",
    "print('stacking_nei_accuracy : %0.2f' % stacking_nei_accuracy )\n",
    "print('stacking_nei_roc_auc : %0.2f' % stacking_nei_roc_auc )\n",
    "\n",
    "print('stacking_nei_Sensitivity : %0.2f' % stacking_nei_sensitivity )\n",
    "print('stacking_nei_Specificity :%0.2f' % stacking_nei_specificity)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test,rownames=['label'],colnames=['predict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "logreg_stacking = LogisticRegression()\n",
    "logreg_stacking.fit(x_train_stacking, y_train)\n",
    "#log_test_y_predicted = logreg.fit(x_train_stacking, y_train).decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_test_y_predicted_pro = logreg_stacking.predict_proba(x_test_stacking)\n",
    "\n",
    "log_score = logreg_test_y_predicted_pro[:, 1]\n",
    "\n",
    "predict_test_lr=[]\n",
    "for i in range(log_score.shape[0]): \n",
    "    if log_score[i]>0.5:\n",
    "        predict_test_lr.append(1)\n",
    "    else:\n",
    "        predict_test_lr.append(0)\n",
    "predict_test_lr = np.array(predict_test_lr)\n",
    "\n",
    "#print(predict_test)\n",
    "\n",
    "fpr, tpr, stacking_lr_roc_auc = roc_curve_and_score(y_test, log_score)\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_lr)\n",
    "\n",
    "stacking_lr_accuracy=(cm1[0,0]+cm1[1,1])/(cm1[1,1]+cm1[0,0]+cm1[0,1]+cm1[1,0])\n",
    "\n",
    "stacking_lr_sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "stacking_lr_specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "\n",
    "#print('Precision:',precision_score(y_test_1, predict_test))\n",
    "#print('Recall:', recall_score(y_test_1, predict_test))\n",
    "#print('f1-score: %f' % f1_score(y_test_1, predict_test))\n",
    "\n",
    "print('stacking_lr_accuracy : %0.2f' % stacking_lr_accuracy )\n",
    "print('stacking_lr_roc_auc : %0.2f' % stacking_lr_roc_auc )\n",
    "\n",
    "print('stacking_lr_sensitivity : %0.2f' % stacking_lr_sensitivity )\n",
    "print('stacking_lr_specificity :%0.2f' % stacking_lr_specificity)\n",
    "\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_lr,rownames=['label'],colnames=['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc  ###計算roc和auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "#plt.grid()\n",
    "\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, log_score)\n",
    "plt.plot(fpr, tpr, color='gray', lw=2,\n",
    "         label='Logistic Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_xgb)\n",
    "plt.plot(fpr, tpr, color='#00db00', lw=2,\n",
    "         label='XGBoost Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_score_stacking)\n",
    "plt.plot(fpr, tpr, color='#ff00ff', lw=2,\n",
    "         label='Random Forest Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, nei_test_y_predicted)\n",
    "plt.plot(fpr, tpr, color='red', lw=2,\n",
    "         label='Nearest Neighbors Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "fpr, tpr, roc_auc = roc_curve_and_score(y_test, predict_pro_stacking)\n",
    "plt.plot(fpr, tpr, color='blue', lw=2,\n",
    "         label='SVM Cardiac AUC={0:.2f}'.format(roc_auc))\n",
    "\n",
    "plt.title('Multi-Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_cxr=pd.read_csv(\"neur_test_all_patients_ca1.csv\")\n",
    "y_predict_cxr=predict_cxr[['predict']].values\n",
    "\n",
    "y_predict_combine=[]\n",
    "\n",
    "#print(predict_pro_stacking)\n",
    "#print(predict_pro_stacking.size)\n",
    "\n",
    "\n",
    "for idx, i in enumerate(predict_pro_stacking):\n",
    "    if y_predict_cxr[idx]==-1:          \n",
    "        y_predict_combine.append(predict_pro_stacking[idx])\n",
    "    else:\n",
    "        y_predict_combine.append((predict_pro_stacking[idx]+y_predict_cxr[idx])/2)\n",
    "        \n",
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "y_predict_combine=np.array(y_predict_combine)\n",
    "print(y_predict_combine.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_combine=[]\n",
    "for i in range(y_predict_combine.shape[0]): \n",
    "    if y_predict_combine[i]>0.5:\n",
    "        predict_test_combine.append(1)\n",
    "    else:\n",
    "        predict_test_combine.append(0)\n",
    "predict_test_combine = np.array(predict_test_combine)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_combine,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_combine)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "svm_accuracy=(cm1[0,0]+cm1[1,1])/(cm1[1,1]+cm1[0,0]+cm1[0,1]+cm1[1,0])\n",
    "\n",
    "\n",
    "fpr, tpr, svm_roc_auc = roc_curve_and_score(y_test, y_predict_combine)\n",
    "\n",
    "svm_specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "svm_sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "\n",
    "print('svm_accuracy_cxr : %0.2f' % svm_accuracy)\n",
    "print('svm_auc_cxr : %0.2f' % svm_roc_auc )\n",
    "print('svm_Sensitivity_cxr : %0.2f' % svm_sensitivity )\n",
    "print('svm_Specificity_cxr :%0.2f' % svm_specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,threshold = roc_curve(y_test, y_predict_combine) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('SVM_stacking LSTM with cxr')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_cxr=pd.read_csv(\"neur_test_all_patients_ca1.csv\")\n",
    "y_predict_cxr=predict_cxr[['predict']].values\n",
    "\n",
    "y_predict_combine_lr=[]\n",
    "\n",
    "for idx, i in enumerate(log_score):\n",
    "    if y_predict_cxr[idx]==-1:          \n",
    "        y_predict_combine_lr.append(log_score[idx])\n",
    "    else:\n",
    "        y_predict_combine_lr.append((log_score[idx]+y_predict_cxr[idx])/2)\n",
    "        \n",
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "y_predict_combine_lr=np.array(y_predict_combine_lr)\n",
    "print(y_predict_combine_lr.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_combine=[]\n",
    "for i in range(y_predict_combine_lr.shape[0]): \n",
    "    if y_predict_combine_lr[i]>0.5:\n",
    "        predict_test_combine.append(1)\n",
    "    else:\n",
    "        predict_test_combine.append(0)\n",
    "predict_test_combine = np.array(predict_test_combine)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_combine,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_combine)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "lr_accuracy=(cm1[0,0]+cm1[1,1])/(cm1[1,1]+cm1[0,0]+cm1[0,1]+cm1[1,0])\n",
    "\n",
    "\n",
    "fpr, tpr, lr_roc_auc = roc_curve_and_score(y_test, y_predict_combine_lr)\n",
    "\n",
    "lr_specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "lr_sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "\n",
    "print('lr_accuracy_cxr : %0.2f' % lr_accuracy)\n",
    "print('lr_auc_cxr : %0.2f' % lr_roc_auc )\n",
    "print('lr_Sensitivity_cxr : %0.2f' % lr_sensitivity )\n",
    "print('lr_Specificity_cxr :%0.2f' % lr_specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_combine=pd.read_csv(\"predict_combine.csv\")\n",
    "#y_predict_combine=predict_combine[['eventV3']].values  \n",
    "#print(y_predict_combine.shape)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_test, y_predict_combine_lr) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('LR_stacking LSTM with cxr')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_cxr=pd.read_csv(\"neur_test_all_patients_ca1.csv\")\n",
    "y_predict_cxr=predict_cxr[['predict']].values\n",
    "\n",
    "y_predict_combine_xg=[]\n",
    "\n",
    "for idx, i in enumerate(y_pred_xgb):\n",
    "    if y_predict_cxr[idx]==-1:          \n",
    "        y_predict_combine_xg.append(y_pred_xgb[idx])\n",
    "    else:\n",
    "        y_predict_combine_xg.append((y_pred_xgb[idx]+y_predict_cxr[idx])/2)\n",
    "        \n",
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "y_predict_combine_xg=np.array(y_predict_combine_xg)\n",
    "print(y_predict_combine_xg.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_combine=[]\n",
    "for i in range(y_predict_combine_xg.shape[0]): \n",
    "    if y_predict_combine_xg[i]>0.5:\n",
    "        predict_test_combine.append(1)\n",
    "    else:\n",
    "        predict_test_combine.append(0)\n",
    "predict_test_combine = np.array(predict_test_combine)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_combine,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_combine)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "xg_accuracy=(cm1[0,0]+cm1[1,1])/(cm1[1,1]+cm1[0,0]+cm1[0,1]+cm1[1,0])\n",
    "\n",
    "\n",
    "fpr, tpr, xg_roc_auc = roc_curve_and_score(y_test, y_predict_combine_xg)\n",
    "\n",
    "xg_specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "xg_sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "\n",
    "print('xg_accuracy_cxr : %0.2f' % xg_accuracy)\n",
    "print('xg_auc_cxr : %0.2f' % xg_roc_auc )\n",
    "print('xg_Sensitivity_cxr : %0.2f' % xg_sensitivity )\n",
    "print('xg_Specificity_cxr :%0.2f' % xg_specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_cxr=pd.read_csv(\"neur_test_all_patients_ca1.csv\")\n",
    "y_predict_cxr=predict_cxr[['predict']].values\n",
    "\n",
    "y_predict_combine_rf=[]\n",
    "\n",
    "for idx, i in enumerate(y_score_stacking):\n",
    "    if y_predict_cxr[idx]==-1:          \n",
    "        y_predict_combine_rf.append(y_score_stacking[idx])\n",
    "    else:\n",
    "        y_predict_combine_rf.append((y_score_stacking[idx]+y_predict_cxr[idx])/2)\n",
    "        \n",
    "y_test_1D=np.array(y_test).reshape(total_test)\n",
    "y_predict_combine_rf=np.array(y_predict_combine_rf)\n",
    "print(y_predict_combine_rf.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_combine=[]\n",
    "for i in range(y_predict_combine_rf.shape[0]): \n",
    "    if y_predict_combine_rf[i]>0.5:\n",
    "        predict_test_combine.append(1)\n",
    "    else:\n",
    "        predict_test_combine.append(0)\n",
    "predict_test_combine = np.array(predict_test_combine)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test_combine,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test_combine)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "rf_accuracy=(cm1[0,0]+cm1[1,1])/(cm1[1,1]+cm1[0,0]+cm1[0,1]+cm1[1,0])\n",
    "\n",
    "\n",
    "fpr, tpr, rf_roc_auc = roc_curve_and_score(y_test, y_predict_combine_rf)\n",
    "\n",
    "rf_specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "rf_sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "\n",
    "print('rf_accuracy_cxr : %0.2f' % rf_accuracy)\n",
    "print('rf_auc_cxr : %0.2f' % rf_roc_auc )\n",
    "print('rf_Sensitivity_cxr : %0.2f' % rf_sensitivity )\n",
    "print('rf_Specificity_cxr :%0.2f' % rf_specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "brier_score=brier_score_loss(y_test, predict_pro_stacking)\n",
    "print(brier_score)\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fop, mpv = calibration_curve(y_test, predict_pro_stacking)\n",
    "#plt.figure()\n",
    "#plt.figure(figsize=(10,10))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot model reliability\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Plots (Stacking by SVM)')\n",
    "plt.plot(mpv, fop, marker='.', label='Brier_score (%1.2f)' % brier_score)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "brier_score=brier_score_loss(y_test, log_score)\n",
    "print(brier_score)\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fop, mpv = calibration_curve(y_test, log_score)\n",
    "#plt.figure()\n",
    "#plt.figure(figsize=(10,10))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot model reliability\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Plots (Stacking by SVM)')\n",
    "plt.plot(mpv, fop, marker='.', label='Brier_score (%1.2f)' % brier_score)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eicu=pd.read_csv(\"baseline_eicu_version2.csv\")  #baseline \n",
    "\n",
    "y_validation=df_eicu['user']\n",
    "\n",
    "x_lstm_validation=eicu_cardiac_total[['vHR','vRR','vsbp','vdbp','vmbp','vspo2']].values \n",
    "\n",
    "#x_lstm_validation=minmax_scale.fit_transform(x_lstm_validation)  #規一化\n",
    "x_lstm_validation=np.array(x_lstm_validation).reshape(total_eicu,T,var) #轉三維  total \n",
    "#x_lstm_validation=np.array(x_lstm_validation).reshape(10665,T,var) #轉三維  total \n",
    "\n",
    "print(x_lstm_validation.shape)\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_1 ,test_acc_1, test_f1_score_1, test_precision_1 = model_1.evaluate(x_lstm_validation,y_validation,\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'test accuracy = {round(test_acc_1 * 100, 4)}%')\n",
    "#print(f'test error = {round((1 - test_acc_1) * 10665)} out of {10665} examples')\n",
    "print(f'test error = {round((1 - test_acc_1) * total_eicu)} out of {total_eicu} examples')\n",
    "\n",
    "validation_pred1= model_1.predict(x_lstm_validation)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation, validation_pred1) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label=' LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_2 ,test_acc_2, test_f1_score_2, test_precision_2 = model_2.evaluate(x_lstm_validation,y_validation,\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'test accuracy = {round(test_acc_2 * 100, 4)}%')\n",
    "#print(f'test error = {round((1 - test_acc_2) * 10665)} out of {10665} examples')\n",
    "print(f'test error = {round((1 - test_acc_2) * total_eicu)} out of {total_eicu} examples')\n",
    "\n",
    "validation_pred2= model_2.predict(x_lstm_validation)\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation, validation_pred2) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label=' LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_3 ,test_acc_3, test_f1_score_3, test_precision_3 = model_3.evaluate(x_lstm_validation,y_validation,\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'test accuracy = {round(test_acc_3 * 100, 4)}%')\n",
    "#print(f'test error = {round((1 - test_acc_3) * 10665)} out of {10665} examples')\n",
    "print(f'test error = {round((1 - test_acc_3) * total_eicu)} out of {total_eicu} examples')\n",
    "\n",
    "validation_pred3= model_3.predict(x_lstm_validation)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation, validation_pred3) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label=' LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_4 ,test_acc_4, test_f1_score_4, test_precision_4 = model_4.evaluate(x_lstm_validation,y_validation,\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'test accuracy = {round(test_acc_4 * 100, 4)}%')\n",
    "#print(f'test error = {round((1 - test_acc_4) * 10665)} out of {10665} examples')\n",
    "print(f'test error = {round((1 - test_acc_4) * total_eicu)} out of {total_eicu} examples')\n",
    "\n",
    "validation_pred4= model_4.predict(x_lstm_validation)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation, validation_pred4) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label=' LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_5 ,test_acc_5, test_f1_score_5, test_precision_5 = model_5.evaluate(x_lstm_validation,y_validation,\n",
    "                                     batch_size=BATCH, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'test accuracy = {round(test_acc_5 * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc_5) * total_eicu)} out of {total_eicu} examples')\n",
    "#print(f'test error = {round((1 - test_acc_5) * 10665)} out of {10665} examples')\n",
    "\n",
    "validation_pred5= model_5.predict(x_lstm_validation)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation, validation_pred5) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label=' LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_temp=np.append(validation_pred1,validation_pred2)\n",
    "pred_temp=np.append(pred_temp,validation_pred3)\n",
    "pred_temp=np.append(pred_temp,validation_pred4)\n",
    "pred_temp=np.append(pred_temp,validation_pred5)\n",
    "\n",
    "#validation_pred_old=np.array(pred_temp).reshape(10668,5, order='F') #轉維\n",
    "validation_pred_old=np.array(pred_temp).reshape(total_eicu,5, order='F') #轉維\n",
    "\n",
    "validation_pred_old= np.mean(validation_pred_old, axis=1)\n",
    " \n",
    "eicu_acc=(test_acc_1+test_acc_2+test_acc_3+test_acc_4+test_acc_5)/5\n",
    "eicu_precision=(test_precision_1+test_precision_2+test_precision_3+test_precision_4+test_precision_5)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation, validation_pred_old) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label=' LSTM ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_validation_1D=np.array(y_validation).reshape(10665)\n",
    "y_validation_1D=np.array(y_validation).reshape(total_eicu)\n",
    "\n",
    "predict_test=[]\n",
    "for i in range(validation_pred_old.shape[0]): \n",
    "    if validation_pred_old[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "pd.crosstab(y_validation_1D,predict_test,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_validation_1D,predict_test)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_eicu=pd.read_csv(\"cascontrol_f2.csv\")  #baseline  baseline_eicu_version2   cascontrol_f2\n",
    "df_eicu=pd.read_csv(\"baseline_eicu_version2.csv\")  #baseline  baseline_eicu_version2   cascontrol_f2\n",
    "\n",
    "df_eicu=df_eicu.drop(['patientunitstayid'],axis=1)\n",
    "df_eicu=df_eicu.drop(['patienthealthsystemstayid'],axis=1)\n",
    "df_eicu=df_eicu.drop(['uniquepid'],axis=1)\n",
    "df_eicu=df_eicu.drop(['CA'],axis=1)\n",
    "df_eicu=df_eicu.drop(['hDied'],axis=1)\n",
    "\n",
    "df_eicu=df_eicu.drop(['BMI'],axis=1)\n",
    "df_eicu=df_eicu.drop(['ccscore'],axis=1)\n",
    "\n",
    "#df_eicu=pd.get_dummies(data=df_eicu,columns=[\"first_careunit\",\"ethnicity\",\"BMI\"])\n",
    "df_eicu=pd.get_dummies(data=df_eicu,columns=[\"first_careunit\",\"ethnicity\"])\n",
    "\n",
    "y_validation_old=df_eicu['user']\n",
    "df_eicu=df_eicu.drop(['user'],axis=1)\n",
    "x_validation_old=df_eicu.values\n",
    "\n",
    "minmax_scale =preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "x_validation_old=minmax_scale.fit_transform(x_validation_old)\n",
    "\n",
    "#predict_validation = forest.predict_proba(x_validation)#给出带有概率值的结果，每个点所有label的概率和为1\n",
    "#y_score_validation_old = predict_validation[:, 1] #RF\n",
    "\n",
    "predict_validation_old = logreg.predict_proba(x_validation_old)\n",
    "y_score_validation_old = predict_validation_old[:, 1]\n",
    "\n",
    "predict_test=[]\n",
    "for i in range(y_score_validation_old.shape[0]): \n",
    "    if y_score_validation_old[i]>0.5:\n",
    "        predict_test.append(1)\n",
    "    else:\n",
    "        predict_test.append(0)\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "y_test_1D=np.array(y_validation_old).reshape(total_eicu)\n",
    "#y_test_1D=np.array(y_validation_old).reshape(10665)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_test,rownames=['label'],colnames=['predict'])  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_test)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_validation_test=np.append(validation_pred_old, y_score_validation_old)\n",
    "#x_validation_stacking=np.array(stacking_validation_test).reshape(10665,2, order='F') #轉維\n",
    "x_validation_stacking=np.array(stacking_validation_test).reshape(total_eicu,2, order='F') #轉維\n",
    "\n",
    "predict=svm_stacking.predict(x_validation_stacking)\n",
    "predict_pro_old=svm_stacking.predict_proba(x_validation_stacking)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_validation_old, predict)\n",
    "precision  = metrics.precision_score(y_validation_old, predict)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict,rownames=['label'],colnames=['predict'])\n",
    "predict_pro_old=predict_pro_old[:,1:2]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "#####from confusion matrix calculate \n",
    "\n",
    "valid_svm_accuracy= (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,1]+cm1[1,0])   #FPR\n",
    "\n",
    "fpr, tpr, valid_svm_roc_auc = roc_curve_and_score(y_validation_old, predict_pro_old)\n",
    "\n",
    "valid_svm_sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "valid_svm_specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "\n",
    "print('valid_svm_accuracy: %0.2f' %valid_svm_accuracy)\n",
    "print('valid_svm_roc_auc: %0.2f' %valid_svm_roc_auc)\n",
    "print('valid_svm_sensitivity: %0.2f' %valid_svm_sensitivity)\n",
    "print('valid_svm_specificity: %0.2f' %valid_svm_specificity)\n",
    "\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation_old, predict_pro_old) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation Eicu (SVM)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "predict_pro_old =pd.DataFrame(predict_pro_old)\n",
    "#predict_pro_old.to_csv('predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lr=logreg_stacking.predict(x_validation_stacking)\n",
    "predict_pro_old_lr=logreg_stacking.predict_proba(x_validation_stacking)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_validation_old, predict_lr)\n",
    "precision  = metrics.precision_score(y_validation_old, predict_lr)\n",
    "\n",
    "pd.crosstab(y_test_1D,predict_lr,rownames=['label'],colnames=['predict'])\n",
    "predict_pro_old_lr=predict_pro_old_lr[:,1:2]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test_1D,predict_lr)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "\n",
    "#####from confusion matrix calculate\n",
    "\n",
    "\n",
    "fpr, tpr, valid_lr_roc_auc = roc_curve_and_score(y_validation_old, predict_pro_old_lr)\n",
    "\n",
    "valid_lr_sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])   #TPR\n",
    "valid_lr_specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])   #FPR\n",
    "\n",
    "ppv =  cm1[1,1]/(cm1[0,1]+cm1[1,1])   \n",
    "npv =  cm1[0,0]/(cm1[0,0]+cm1[1,0])  \n",
    "\n",
    "valid_lr_accuracy= (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,1]+cm1[1,0])   #FPR\n",
    "\n",
    "print('valid_lr_accuracy: %0.2f' %valid_lr_accuracy)\n",
    "print('valid_lr_roc_auc: %0.2f' %valid_lr_roc_auc)\n",
    "print('valid_lr_sensitivity: %0.2f' %valid_lr_sensitivity)\n",
    "print('valid_lr_specificity: %0.2f' %valid_lr_specificity)\n",
    "\n",
    "print('ppv:',ppv)\n",
    "print('npv:',npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr,tpr,threshold = roc_curve(y_validation_old, predict_pro_old_lr) ###計算真正率和假正率\n",
    "roc_auc = auc(fpr,tpr) ###計算auc的值\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率為橫座標，真正率為縱座標做曲線\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation Eicu (LR)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "predict_pro_old_lr =pd.DataFrame(predict_pro_old_lr)\n",
    "#predict_pro_old.to_csv('predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('smote_accuracy:%0.2f' %smote_accuracy)\n",
    "print('smote_auc:  %0.2f' %smote_roc_auc)\n",
    "print('smote_sensitivity : %0.2f' %smote_sensitivity)\n",
    "print('smote_specificity : %0.2f\\n' %smote_specificity)\n",
    "\n",
    "print('nr_accuracy: %0.2f' %nr_accuracy)\n",
    "print('nr_auc: %0.2f' %nr_roc_auc)\n",
    "print('nr_sensitivity: %0.2f' %nr_sensitivity)\n",
    "print('nr_specificity: %0.2f\\n' %nr_specificity)\n",
    "\n",
    "print('5_fold_accuracy : %0.2f' %accuracy_5_fold)  #accuracy\n",
    "print('5_fold_auc : %0.2f' %fold_roc_auc)  #accuracy\n",
    "print('5_fold_sensitivity: %0.2f' %sensitivity_5_fold)\n",
    "print('5_fold_specificity: %0.2f\\n' %specificity_5_fold)\n",
    "\n",
    "print('stacking_svm_Accuracy: %0.2f' %stacking_svm_accuracy)\n",
    "print('stacking_svm_auc: %0.2f' %stacking_svm_roc_auc)\n",
    "print('stacking_svm_sensitivity: %0.2f' %stacking_svm_sensitivity)\n",
    "print('stacking_svm_specificity: %0.2f' %stacking_svm_specificity)\n",
    "print('svm_accuracy_cxr : %0.2f' % svm_accuracy)\n",
    "print('svm_auc_cxr : %0.2f' % svm_roc_auc )\n",
    "print('svm_Sensitivity_cxr : %0.2f' % svm_sensitivity )\n",
    "print('svm_Specificity_cxr :%0.2f\\n' % svm_specificity)\n",
    "\n",
    "print('stacking_lr_Accuracy: %0.2f' %stacking_lr_accuracy)\n",
    "print('stacking_lr_auc: %0.2f' %stacking_lr_roc_auc)\n",
    "print('stacking_lr_sensitivity: %0.2f' %stacking_lr_sensitivity)\n",
    "print('stacking_lr_specificity: %0.2f' %stacking_lr_specificity)\n",
    "print('lr_accuracy_cxr : %0.2f' % lr_accuracy)\n",
    "print('lr_auc_cxr : %0.2f' % lr_roc_auc )\n",
    "print('lr_Sensitivity_cxr : %0.2f' % lr_sensitivity )\n",
    "print('lr_Specificity_cxr :%0.2f\\n' % lr_specificity)\n",
    "\n",
    "print('stacking_xg_Accuracy: %0.2f' %stacking_xg_accuracy)\n",
    "print('stacking_xg_auc: %0.2f' %stacking_xg_roc_auc)\n",
    "print('stacking_xg_sensitivity: %0.2f' %stacking_xg_sensitivity)\n",
    "print('stacking_xg_specificity: %0.2f' %stacking_xg_specificity)\n",
    "print('xg_accuracy_cxr : %0.2f' % xg_accuracy)\n",
    "print('xg_auc_cxr : %0.2f' % xg_roc_auc )\n",
    "print('xg_Sensitivity_cxr : %0.2f' % xg_sensitivity )\n",
    "print('xg_Specificity_cxr :%0.2f\\n' % xg_specificity)\n",
    "\n",
    "print('stacking_rf_Accuracy: %0.2f' %stacking_rf_accuracy)\n",
    "print('stacking_rf_auc: %0.2f' %stacking_rf_roc_auc)\n",
    "print('stacking_rf_sensitivity: %0.2f' %stacking_rf_sensitivity)\n",
    "print('stacking_rf_specificity: %0.2f' %stacking_rf_specificity)\n",
    "print('rf_accuracy_cxr : %0.2f' % rf_accuracy)\n",
    "print('rf_auc_cxr : %0.2f' % rf_roc_auc )\n",
    "print('rf_Sensitivity_cxr : %0.2f' % rf_sensitivity )\n",
    "print('rf_Specificity_cxr :%0.2f\\n' % rf_specificity)\n",
    "\n",
    "print('valid_svm_accuracy: %0.2f' %valid_svm_accuracy)\n",
    "print('valid_svm_roc_auc: %0.2f' %valid_svm_roc_auc)\n",
    "print('valid_svm_sensitivity: %0.2f' %valid_svm_sensitivity)\n",
    "print('valid_svm_specificity: %0.2f\\n' %valid_svm_specificity)\n",
    "\n",
    "print('valid_lr_accuracy: %0.2f' %valid_lr_accuracy)\n",
    "print('valid_lr_roc_auc: %0.2f' %valid_lr_roc_auc)\n",
    "print('valid_lr_sensitivity: %0.2f' %valid_lr_sensitivity)\n",
    "print('valid_lr_specificity: %0.2f' %valid_lr_specificity)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_avg=pd.DataFrame(x_test_stacking)\n",
    "#test_avg.to_csv('test_avg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_pro_stacking_pri=pd.DataFrame(predict_pro_stacking)\n",
    "#predict_pro_stacking_pri.to_csv('predict_pro_stacking_pri.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
