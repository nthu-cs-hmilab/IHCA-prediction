{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66be304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "X_test_2D:  (10000, 784)\n",
      "Epoch 1/10\n",
      "60/60 - 4s - loss: 0.7711 - accuracy: 0.8112 - val_loss: 0.3221 - val_accuracy: 0.9119\n",
      "Epoch 2/10\n",
      "60/60 - 1s - loss: 0.2983 - accuracy: 0.9161 - val_loss: 0.2502 - val_accuracy: 0.9313\n",
      "Epoch 3/10\n",
      "60/60 - 1s - loss: 0.2362 - accuracy: 0.9342 - val_loss: 0.2088 - val_accuracy: 0.9417\n",
      "Epoch 4/10\n",
      "60/60 - 1s - loss: 0.1963 - accuracy: 0.9445 - val_loss: 0.1809 - val_accuracy: 0.9497\n",
      "Epoch 5/10\n",
      "60/60 - 0s - loss: 0.1670 - accuracy: 0.9528 - val_loss: 0.1613 - val_accuracy: 0.9544\n",
      "Epoch 6/10\n",
      "60/60 - 0s - loss: 0.1431 - accuracy: 0.9601 - val_loss: 0.1464 - val_accuracy: 0.9570\n",
      "Epoch 7/10\n",
      "60/60 - 1s - loss: 0.1248 - accuracy: 0.9651 - val_loss: 0.1351 - val_accuracy: 0.9614\n",
      "Epoch 8/10\n",
      "60/60 - 1s - loss: 0.1099 - accuracy: 0.9694 - val_loss: 0.1220 - val_accuracy: 0.9649\n",
      "Epoch 9/10\n",
      "60/60 - 1s - loss: 0.0974 - accuracy: 0.9731 - val_loss: 0.1175 - val_accuracy: 0.9660\n",
      "Epoch 10/10\n",
      "60/60 - 1s - loss: 0.0877 - accuracy: 0.9763 - val_loss: 0.1104 - val_accuracy: 0.9670\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1029 - accuracy: 0.9696\n",
      "\n",
      "\t[Info] Accuracy of testing data = 97.0%\n",
      "[7 2 1 0 4 1 4 9 6 9]\n"
     ]
    }
   ],
   "source": [
    "# 導入函式庫\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils  # 用來後續將 label 標籤轉為 one-hot-encoding\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# 載入 MNIST 資料庫的訓練資料，並自動分為『訓練組』及『測試組』\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "#cv2.imwrite('C:/Users/User/Desktop/output.jpg', X_test[1])\n",
    "\n",
    "# 建立簡單的線性執行的模型\n",
    "model = Sequential()\n",
    "\n",
    "# Add Input layer, 隱藏層(hidden layer) 有 256個輸出變數\n",
    "model.add(Dense(units=256, input_dim=784, kernel_initializer='normal', activation='relu'))\n",
    "# Add output layer\n",
    "model.add(Dense(units=10, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "# 編譯: 選擇損失函數、優化方法及成效衡量方式\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 將 training 的 label 進行 one-hot encoding，例如數字 7 經過 One-hot encoding 轉換後是 0000001000，即第7個值為 1\n",
    "y_TrainOneHot = np_utils.to_categorical(y_train)\n",
    "y_TestOneHot = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 將 training 的 input 資料轉為2維\n",
    "#X_train_2D = X_train.reshape(60000, 28*28).astype('float32')\n",
    "#X_test_2D = X_test.reshape(10000, 28*28).astype('float32')\n",
    "\n",
    "print(\"X_test_2D: \",X_test_2D.shape)\n",
    "\n",
    "x_Train_norm = X_train_2D/255\n",
    "x_Test_norm = X_test_2D/255\n",
    "\n",
    "# 進行訓練, 訓練過程會存在 train_history 變數中\n",
    "train_history = model.fit(x=x_Train_norm, y=y_TrainOneHot, validation_split=0.2, epochs=10, batch_size=800, verbose=2)\n",
    "\n",
    "# 顯示訓練成果(分數)\n",
    "scores = model.evaluate(x_Test_norm, y_TestOneHot)\n",
    "print()\n",
    "print(\"\\t[Info] Accuracy of testing data = {:2.1f}%\".format(scores[1]*100.0))\n",
    "\n",
    "\n",
    "# 預測(prediction)\n",
    "X = x_Test_norm[0:10,:]\n",
    "predictions = model.predict_classes(X)\n",
    "# get prediction result\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6894af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_cnn():\n",
    "    easy_model = Sequential()\n",
    "    easy_model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "    easy_model.add(BatchNormalization())\n",
    "    easy_model.add(MaxPool2D((2, 2),padding='same'))\n",
    "    easy_model.add(Activation('relu'))\n",
    "    for i in range(3):\n",
    "        easy_model.add(Conv2D(32, (3, 3)))\n",
    "        easy_model.add(BatchNormalization())\n",
    "        easy_model.add(MaxPool2D((2, 2),padding='same'))\n",
    "        easy_model.add(Activation('relu'))\n",
    "    easy_model.add(Flatten())\n",
    "    easy_model.add(Dense(10,activation='sigmoid', kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "    easy_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "    return easy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d73ccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "X_test_2D:  (10000, 28, 28, 1)\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                250890    \n",
      "=================================================================\n",
      "Total params: 251,210\n",
      "Trainable params: 251,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "60/60 - 4s - loss: 0.6354 - accuracy: 0.8399 - val_loss: 0.2832 - val_accuracy: 0.9203\n",
      "Epoch 2/5\n",
      "60/60 - 0s - loss: 0.2550 - accuracy: 0.9263 - val_loss: 0.2099 - val_accuracy: 0.9420\n",
      "Epoch 3/5\n",
      "60/60 - 3s - loss: 0.1808 - accuracy: 0.9491 - val_loss: 0.1554 - val_accuracy: 0.9590\n",
      "Epoch 4/5\n",
      "60/60 - 0s - loss: 0.1338 - accuracy: 0.9631 - val_loss: 0.1268 - val_accuracy: 0.9661\n",
      "Epoch 5/5\n",
      "60/60 - 0s - loss: 0.1048 - accuracy: 0.9716 - val_loss: 0.1082 - val_accuracy: 0.9721\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Conv2D\n",
    "from keras.utils import np_utils  # 用來後續將 label 標籤轉為 one-hot-encoding\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# 載入 MNIST 資料庫的訓練資料，並自動分為『訓練組』及『測試組』\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "#cv2.imwrite('C:/Users/User/Desktop/output.jpg', X_test[1])\n",
    "\n",
    "# 建立簡單的線性執行的模型\n",
    "model = Sequential()\n",
    "\n",
    "# Add Input layer, 隱藏層(hidden layer) 有 256個輸出變數\n",
    "model.add(Dense(units=256, input_dim=784, kernel_initializer='normal', activation='relu'))\n",
    "# Add output layer\n",
    "model.add(Dense(units=10, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "# 編譯: 選擇損失函數、優化方法及成效衡量方式\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 將 training 的 label 進行 one-hot encoding，例如數字 7 經過 One-hot encoding 轉換後是 0000001000，即第7個值為 1\n",
    "y_TrainOneHot = np_utils.to_categorical(y_train)\n",
    "y_TestOneHot = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 將 training 的 input 資料轉為2維\n",
    "X_train_2D = X_train.reshape(60000, 28,28,1).astype('float32')\n",
    "X_test_2D = X_test.reshape(10000, 28,28,1).astype('float32')\n",
    "\n",
    "print(\"X_test_2D: \",X_test_2D.shape)\n",
    "\n",
    "x_Train_norm = X_train_2D/255\n",
    "x_Test_norm = X_test_2D/255\n",
    "\n",
    "#####################建立model#########################\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=3, input_shape=(28, 28,1), activation='relu', padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(MaxPool2D(pool_size=(2,2)))\n",
    "          \n",
    "model.add(Flatten())\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "####################建立model#########################\n",
    "\n",
    "#model=easy_cnn()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "train_history = model.fit(x=x_Train_norm, y=y_TrainOneHot, validation_split=0.2, epochs=5, batch_size=800, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47696147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c2ccc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb915a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
